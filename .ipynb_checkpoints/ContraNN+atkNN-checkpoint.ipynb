{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "e9ab7b6e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "import prettytable as pt\n",
    "%run helpers_preproc.ipynb\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2719b0",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b34c00ab",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "origDataDir = 'SHREC11/'\n",
    "newDataDir = 'SHREC11_plus/'\n",
    "K = 5\n",
    "radiuss = [0.0002,0.0004,0.0008]\n",
    "train_size = 450 * len(radiuss)\n",
    "test_size = (600-450) * len(radiuss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684373cc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 1. expand dataset and scramble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "848dd975",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "expand(origDataDir, newDataDir, radiuss)\n",
    "scramble(newDataDir, 10000,600 * len(radiuss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca467ac",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 2. read in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51110c1a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2.1 read in v (252 x 3),f (...x...) and cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1428b3a4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "/var/folders/y9/sgsdqvs575j76jqnz728mwkh0000gn/T/ipykernel_14679/2399023897.py:12: RuntimeWarning: invalid value encountered in divide\n",
=======
      "/var/folders/t4/vdzymfw562g8ml8ks_2b5l5r0000gn/T/ipykernel_14613/2399023897.py:12: RuntimeWarning: invalid value encountered in true_divide\n",
>>>>>>> main
      "  normed_adj = adj / np.reshape(np.sum(adj,axis = 0),[252,1])\n"
     ]
    }
   ],
   "source": [
    "ver_list = []\n",
    "adj_list = []\n",
    "Nadj_list = []\n",
    "gMat_list = []\n",
    "gLbl_list = []\n",
    "\n",
    "for i in range(600 * len(radiuss)):\n",
    "    v, f = get_nodes(newDataDir + 'T' + str(i) + '.obj')\n",
    "    group_mat, group_labels = K_mean_cluster(v, K)\n",
    "    \n",
    "    adj = get_adj_from_f(f)            \n",
    "    normed_adj = adj / np.reshape(np.sum(adj,axis = 0),[252,1])\n",
    "    ver_list.append(v)\n",
    "    adj_list.append(adj)\n",
    "    Nadj_list.append(normed_adj)\n",
    "    gMat_list.append(group_mat)\n",
    "    gLbl_list.append(group_labels)\n",
    "    \n",
    "    \n",
    "vers = np.array(ver_list)\n",
    "adjs = np.array(adj_list)\n",
    "Nadjs = np.array(Nadj_list)\n",
    "gMats = np.array(gMat_list)\n",
    "gLbls = np.array(gLbl_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013d531c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2.2 Read in the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3d47dac9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "label_np = np.array(readLbl(600 * len(radiuss),newDataDir+'labels.txt'))\n",
    "label_np_train = label_np[:train_size]\n",
    "label_np_test = label_np[train_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5329a9ea",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2.3 Split into training set and testing set"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 58,
=======
   "execution_count": 6,
>>>>>>> main
   "id": "bb6dcc36",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "vers_train = torch.tensor(vers[:train_size]).float()\n",
    "adjs_train = torch.tensor(adjs[:train_size]).float()\n",
    "nadjs_train = torch.nan_to_num(torch.tensor(Nadjs[:train_size]).float(),0,0,0)\n",
    "gMats_train = torch.tensor(gMats[:train_size]).float()\n",
    "label_train = torch.tensor(label_np_train).float()\n",
    "\n",
    "vers_test = torch.tensor(vers[train_size:]).float()\n",
    "adjs_test = torch.tensor(adjs[train_size:]).float()\n",
    "nadjs_test = torch.nan_to_num(torch.tensor(Nadjs[train_size:]).float(),0,0,0)\n",
    "gMats_test = torch.tensor(gMats[train_size:]).float()\n",
    "label_test = torch.tensor(label_np_test).float()\n",
    "\n",
    "label_mat_train = torch.tensor(np.where(igl.all_pairs_distances(label_np_train,label_np_train,False) > 0.5,0,1)).float()\n",
    "label_mat_test = torch.tensor(np.where(igl.all_pairs_distances(label_np_test,label_np_test,False) > 0.5,0,1)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fea6b4a9",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "#detect_nan(label_mat_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3e64d719",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([450, 450])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#label_mat_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2ec635db",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "#print message about training and testing dataset\n",
    "# print(vers_train.shape)\n",
    "# print(adjs_train.shape)\n",
    "# print(nadjs_train.shape)\n",
    "# print(gMats_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5759f9c",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "58ac61b4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 3. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b06f3bb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 3.1 Hyperparameters for training"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 62,
=======
   "execution_count": 10,
>>>>>>> main
   "id": "5af46682",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "contraGWs = [5,5,5,5]\n",
    "contraMWs = [5,5,5,5]\n",
    "atkGWs = [5,5,5,5]\n",
    "atkMWs = [5,5,5,K * 3 + 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e6cccc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 3.2 Initialize neural networks"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 63,
=======
   "execution_count": 84,
>>>>>>> main
   "id": "832b8db7",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%run NNs.ipynb\n",
    "%run helpers_preproc.ipynb\n",
    "contraG = GCN(3,contraGWs)\n",
    "contraM = MLP(252* contraGWs[len(contraGWs)-1],contraMWs)\n",
    "atkG = GCN(3,atkGWs)\n",
    "atkM = MLP_atk(252* atkGWs[len(contraGWs)-1], 10, K, atkMWs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee6d557",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1510530",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 3.4 Extract node-level features from clean data"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 28,
=======
   "execution_count": 85,
>>>>>>> main
   "id": "9ca6bd8a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "feas_clean = extract_node_feature(vers_train,adjs_train)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 29,
=======
   "execution_count": 86,
>>>>>>> main
   "id": "f9ce8f8a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%run L.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bed8497",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 3.5 Feed clean data into contraNNðŸ¤ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513d148f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 3.6 Train atkNNðŸ˜ˆ with contraNNðŸ¤ "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 30,
=======
   "execution_count": 87,
>>>>>>> main
   "id": "f5d3147c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "atkLR = 0.0001\n",
    "contraLR = 0.0001\n",
    "torch.set_printoptions(precision=10)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 31,
=======
   "execution_count": 89,
>>>>>>> main
   "id": "4e942233",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "\t loss \t\t same mean \t diff mean \t same std\n",
      "A:ðŸ˜ˆ \t 2e-05 \t 0.01184 \t 0.01312 \t 0.06496\n",
      "A:ðŸ˜ˆ \t 2e-05 \t 0.01184 \t 0.01312 \t 0.06495\n",
      "A:ðŸ˜ˆ \t 2e-05 \t 0.01184 \t 0.01312 \t 0.06496\n",
      "A:ðŸ˜ˆ \t 2e-05 \t 0.01184 \t 0.01312 \t 0.06496\n",
      "A:ðŸ˜ˆ \t 2e-05 \t 0.01184 \t 0.01312 \t 0.06495\n",
      "A:ðŸ˜ˆ \t 2e-05 \t 0.01184 \t 0.01312 \t 0.06494\n",
      "A:ðŸ˜ˆ \t 2e-05 \t 0.01184 \t 0.01312 \t 0.06495\n",
      "A:ðŸ˜ˆ \t 2e-05 \t 0.01184 \t 0.01312 \t 0.06496\n",
      "A:ðŸ˜ˆ \t 2e-05 \t 0.01184 \t 0.01312 \t 0.06496\n",
      "A:ðŸ˜ˆ \t 2e-05 \t 0.01184 \t 0.01312 \t 0.06495\n",
      "\t loss \t\t same mean \t diff mean \t same std\n",
      "C:ðŸ¤  \t 2e-05 \t 0.01184 \t 0.01311 \t 0.06494\n",
      "C:ðŸ¤  \t 1e-05 \t 0.01175 \t 0.01304 \t 0.06449\n",
      "C:ðŸ¤  \t -1e-05 \t 0.01166 \t 0.01295 \t 0.06398\n",
      "C:ðŸ¤  \t -2e-05 \t 0.01157 \t 0.01286 \t 0.06349\n",
      "C:ðŸ¤  \t -4e-05 \t 0.01147 \t 0.01277 \t 0.06295\n",
      "C:ðŸ¤  \t -5e-05 \t 0.01138 \t 0.01268 \t 0.06244\n",
      "C:ðŸ¤  \t -7e-05 \t 0.01128 \t 0.01258 \t 0.0619\n",
      "C:ðŸ¤  \t -8e-05 \t 0.01118 \t 0.01249 \t 0.06134\n",
      "C:ðŸ¤  \t -1e-04 \t 0.01107 \t 0.01238 \t 0.06075\n",
      "C:ðŸ¤  \t -0.00011 \t 0.01096 \t 0.01228 \t 0.06017\n",
      "\t loss \t\t same mean \t diff mean \t same std\n",
      "A:ðŸ˜ˆ \t -0.00013 \t 0.01085 \t 0.01217 \t 0.05954\n",
      "A:ðŸ˜ˆ \t -0.00013 \t 0.01085 \t 0.01217 \t 0.05953\n",
      "A:ðŸ˜ˆ \t -0.00013 \t 0.01084 \t 0.01216 \t 0.05952\n",
      "A:ðŸ˜ˆ \t -0.00013 \t 0.01084 \t 0.01216 \t 0.05952\n",
      "A:ðŸ˜ˆ \t -0.00012 \t 0.01085 \t 0.01216 \t 0.05956\n",
      "A:ðŸ˜ˆ \t -0.00013 \t 0.01085 \t 0.01216 \t 0.05954\n",
      "A:ðŸ˜ˆ \t -0.00013 \t 0.01084 \t 0.01216 \t 0.05952\n",
      "A:ðŸ˜ˆ \t -0.00012 \t 0.01085 \t 0.01216 \t 0.05956\n",
      "A:ðŸ˜ˆ \t -0.00013 \t 0.01084 \t 0.01216 \t 0.05953\n",
      "A:ðŸ˜ˆ \t -0.00013 \t 0.01084 \t 0.01216 \t 0.05952\n",
      "\t loss \t\t same mean \t diff mean \t same std\n",
      "C:ðŸ¤  \t -0.00013 \t 0.01084 \t 0.01216 \t 0.05952\n",
      "C:ðŸ¤  \t -0.00014 \t 0.01073 \t 0.01204 \t 0.0589\n",
      "C:ðŸ¤  \t -0.00016 \t 0.0106 \t 0.01193 \t 0.05823\n",
      "C:ðŸ¤  \t -0.00017 \t 0.01048 \t 0.0118 \t 0.05755\n",
      "C:ðŸ¤  \t -0.00018 \t 0.01036 \t 0.01168 \t 0.05689\n",
      "C:ðŸ¤  \t -0.0002 \t 0.01023 \t 0.01156 \t 0.05621\n",
      "C:ðŸ¤  \t -0.00021 \t 0.01011 \t 0.01143 \t 0.05552\n",
      "C:ðŸ¤  \t -0.00022 \t 0.00998 \t 0.0113 \t 0.05484\n",
      "C:ðŸ¤  \t -0.00023 \t 0.00986 \t 0.01117 \t 0.05416\n",
      "C:ðŸ¤  \t -0.00024 \t 0.00973 \t 0.01104 \t 0.05349\n",
      "\t loss \t\t same mean \t diff mean \t same std\n",
      "A:ðŸ˜ˆ \t -0.00026 \t 0.0096 \t 0.01092 \t 0.05278\n",
      "A:ðŸ˜ˆ \t -0.00026 \t 0.0096 \t 0.01092 \t 0.05278\n",
      "A:ðŸ˜ˆ \t -0.00025 \t 0.00961 \t 0.01092 \t 0.05281\n",
      "A:ðŸ˜ˆ \t -0.00026 \t 0.0096 \t 0.01092 \t 0.0528\n",
      "A:ðŸ˜ˆ \t -0.00026 \t 0.0096 \t 0.01092 \t 0.05277\n",
      "A:ðŸ˜ˆ \t -0.00026 \t 0.0096 \t 0.01092 \t 0.05277\n",
      "A:ðŸ˜ˆ \t -0.00026 \t 0.0096 \t 0.01092 \t 0.05278\n",
      "A:ðŸ˜ˆ \t -0.00026 \t 0.0096 \t 0.01092 \t 0.05279\n",
      "A:ðŸ˜ˆ \t -0.00026 \t 0.0096 \t 0.01092 \t 0.0528\n",
      "A:ðŸ˜ˆ \t -0.00026 \t 0.0096 \t 0.01092 \t 0.05278\n",
      "\t loss \t\t same mean \t diff mean \t same std\n",
      "C:ðŸ¤  \t -0.00026 \t 0.0096 \t 0.01092 \t 0.05274\n",
      "C:ðŸ¤  \t -0.00028 \t 0.00947 \t 0.01079 \t 0.05205\n",
      "C:ðŸ¤  \t -0.00028 \t 0.00935 \t 0.01066 \t 0.0514\n",
      "C:ðŸ¤  \t -0.0003 \t 0.00922 \t 0.01053 \t 0.0507\n",
      "C:ðŸ¤  \t -0.00031 \t 0.00909 \t 0.01041 \t 0.05001\n",
      "C:ðŸ¤  \t -0.00032 \t 0.00897 \t 0.01028 \t 0.04934\n",
      "C:ðŸ¤  \t -0.00034 \t 0.00885 \t 0.01016 \t 0.0487\n",
      "C:ðŸ¤  \t -0.00035 \t 0.00873 \t 0.01004 \t 0.04808\n",
      "C:ðŸ¤  \t -0.00036 \t 0.00861 \t 0.00993 \t 0.04741\n",
      "C:ðŸ¤  \t -0.00037 \t 0.0085 \t 0.00981 \t 0.04683\n",
      "\t loss \t\t same mean \t diff mean \t same std\n",
      "A:ðŸ˜ˆ \t -0.00039 \t 0.00839 \t 0.0097 \t 0.04617\n",
      "A:ðŸ˜ˆ \t -0.00039 \t 0.00839 \t 0.0097 \t 0.0462\n",
      "A:ðŸ˜ˆ \t -0.00039 \t 0.00839 \t 0.00971 \t 0.04622\n",
      "A:ðŸ˜ˆ \t -0.00039 \t 0.00839 \t 0.00971 \t 0.04622\n",
      "A:ðŸ˜ˆ \t -0.00039 \t 0.00839 \t 0.00971 \t 0.0462\n",
      "A:ðŸ˜ˆ \t -0.00039 \t 0.00839 \t 0.00971 \t 0.04623\n",
      "A:ðŸ˜ˆ \t -0.00039 \t 0.00839 \t 0.00971 \t 0.04621\n",
      "A:ðŸ˜ˆ \t -0.00039 \t 0.00839 \t 0.00971 \t 0.04619\n",
      "A:ðŸ˜ˆ \t -0.00039 \t 0.0084 \t 0.00971 \t 0.04624\n",
      "A:ðŸ˜ˆ \t -0.0004 \t 0.00839 \t 0.00971 \t 0.04617\n",
      "\t loss \t\t same mean \t diff mean \t same std\n",
      "C:ðŸ¤  \t -0.00039 \t 0.00839 \t 0.00971 \t 0.04621\n",
      "C:ðŸ¤  \t -0.00041 \t 0.00828 \t 0.0096 \t 0.04561\n",
      "C:ðŸ¤  \t -0.00042 \t 0.00819 \t 0.0095 \t 0.04509\n",
      "C:ðŸ¤  \t -0.00043 \t 0.00808 \t 0.00941 \t 0.04452\n",
      "C:ðŸ¤  \t -0.00045 \t 0.00798 \t 0.00931 \t 0.044\n",
      "C:ðŸ¤  \t -0.00045 \t 0.0079 \t 0.00922 \t 0.04356\n",
      "C:ðŸ¤  \t -0.00047 \t 0.00781 \t 0.00914 \t 0.04304\n",
      "C:ðŸ¤  \t -0.00049 \t 0.00772 \t 0.00906 \t 0.04255\n",
      "C:ðŸ¤  \t -0.00049 \t 0.00764 \t 0.00898 \t 0.04217\n",
      "C:ðŸ¤  \t -0.0005 \t 0.00757 \t 0.00891 \t 0.04177\n",
      "\t loss \t\t same mean \t diff mean \t same std\n",
      "A:ðŸ˜ˆ \t -0.00052 \t 0.00749 \t 0.00884 \t 0.04136\n",
      "A:ðŸ˜ˆ \t -0.00052 \t 0.00749 \t 0.00884 \t 0.04138\n",
      "A:ðŸ˜ˆ \t -0.00052 \t 0.00749 \t 0.00884 \t 0.04134\n",
      "A:ðŸ˜ˆ \t -0.00052 \t 0.0075 \t 0.00884 \t 0.0414\n",
      "A:ðŸ˜ˆ \t -0.00052 \t 0.0075 \t 0.00884 \t 0.0414\n",
      "A:ðŸ˜ˆ \t -0.00052 \t 0.00749 \t 0.00884 \t 0.04136\n",
      "A:ðŸ˜ˆ \t -0.00052 \t 0.00749 \t 0.00884 \t 0.04134\n",
      "A:ðŸ˜ˆ \t -0.00052 \t 0.00749 \t 0.00884 \t 0.04136\n",
      "A:ðŸ˜ˆ \t -0.00052 \t 0.00749 \t 0.00884 \t 0.04137\n",
      "A:ðŸ˜ˆ \t -0.00052 \t 0.00749 \t 0.00884 \t 0.04137\n",
      "\t loss \t\t same mean \t diff mean \t same std\n",
      "C:ðŸ¤  \t -0.00052 \t 0.00749 \t 0.00884 \t 0.04135\n",
      "C:ðŸ¤  \t -0.00054 \t 0.00742 \t 0.00878 \t 0.04097\n",
      "C:ðŸ¤  \t -0.00055 \t 0.00736 \t 0.00872 \t 0.04065\n",
      "C:ðŸ¤  \t -0.00056 \t 0.00729 \t 0.00866 \t 0.04029\n",
      "C:ðŸ¤  \t -0.00057 \t 0.00724 \t 0.00861 \t 0.03999\n",
      "C:ðŸ¤  \t -0.00058 \t 0.00718 \t 0.00856 \t 0.03973\n",
      "C:ðŸ¤  \t -0.0006 \t 0.00713 \t 0.00852 \t 0.03947\n",
      "C:ðŸ¤  \t -0.00061 \t 0.00709 \t 0.00848 \t 0.03921\n",
      "C:ðŸ¤  \t -0.00062 \t 0.00705 \t 0.00845 \t 0.03903\n",
      "C:ðŸ¤  \t -0.00064 \t 0.007 \t 0.00842 \t 0.03878\n",
      "\t loss \t\t same mean \t diff mean \t same std\n",
      "A:ðŸ˜ˆ \t -0.00064 \t 0.00697 \t 0.00839 \t 0.03863\n",
      "A:ðŸ˜ˆ \t -0.00065 \t 0.00697 \t 0.00839 \t 0.0386\n",
      "A:ðŸ˜ˆ \t -0.00065 \t 0.00697 \t 0.00839 \t 0.03859\n",
      "A:ðŸ˜ˆ \t -0.00065 \t 0.00697 \t 0.00839 \t 0.03862\n",
      "A:ðŸ˜ˆ \t -0.00064 \t 0.00697 \t 0.00839 \t 0.03863\n",
      "A:ðŸ˜ˆ \t -0.00065 \t 0.00697 \t 0.00839 \t 0.03858\n",
      "A:ðŸ˜ˆ \t -0.00065 \t 0.00697 \t 0.00839 \t 0.03857\n",
      "A:ðŸ˜ˆ \t -0.00065 \t 0.00697 \t 0.00839 \t 0.03857\n",
      "A:ðŸ˜ˆ \t -0.00064 \t 0.00697 \t 0.00839 \t 0.03863\n",
      "A:ðŸ˜ˆ \t -0.00065 \t 0.00697 \t 0.00839 \t 0.03862\n",
      "\t loss \t\t same mean \t diff mean \t same std\n",
      "C:ðŸ¤  \t -0.00065 \t 0.00697 \t 0.00839 \t 0.03862\n",
      "C:ðŸ¤  \t -0.00066 \t 0.00694 \t 0.00837 \t 0.03844\n",
      "C:ðŸ¤  \t -0.00068 \t 0.0069 \t 0.00835 \t 0.03825\n",
      "C:ðŸ¤  \t -0.00069 \t 0.00688 \t 0.00833 \t 0.03815\n",
      "C:ðŸ¤  \t -0.0007 \t 0.00686 \t 0.00832 \t 0.03803\n",
      "C:ðŸ¤  \t -0.00071 \t 0.00684 \t 0.00831 \t 0.03797\n",
      "C:ðŸ¤  \t -0.00072 \t 0.00683 \t 0.0083 \t 0.03788\n",
      "C:ðŸ¤  \t -0.00073 \t 0.00681 \t 0.0083 \t 0.03781\n",
      "C:ðŸ¤  \t -0.00075 \t 0.0068 \t 0.0083 \t 0.03773\n",
      "C:ðŸ¤  \t -0.00076 \t 0.00679 \t 0.0083 \t 0.03772\n",
      "\t loss \t\t same mean \t diff mean \t same std\n",
      "A:ðŸ˜ˆ \t -0.00077 \t 0.00678 \t 0.00831 \t 0.03767\n",
      "A:ðŸ˜ˆ \t -0.00077 \t 0.00679 \t 0.00831 \t 0.0377\n",
      "A:ðŸ˜ˆ \t -0.00077 \t 0.00679 \t 0.00831 \t 0.03772\n",
      "A:ðŸ˜ˆ \t -0.00077 \t 0.00679 \t 0.00831 \t 0.03771\n",
      "A:ðŸ˜ˆ \t -0.00077 \t 0.00679 \t 0.00831 \t 0.03773\n",
      "A:ðŸ˜ˆ \t -0.00077 \t 0.00679 \t 0.00831 \t 0.03771\n",
      "A:ðŸ˜ˆ \t -0.00077 \t 0.00679 \t 0.00831 \t 0.03772\n",
      "A:ðŸ˜ˆ \t -0.00077 \t 0.00679 \t 0.00831 \t 0.03772\n",
      "A:ðŸ˜ˆ \t -0.00077 \t 0.00679 \t 0.00831 \t 0.03771\n",
      "A:ðŸ˜ˆ \t -0.00077 \t 0.00679 \t 0.00831 \t 0.0377\n",
      "\t loss \t\t same mean \t diff mean \t same std\n",
      "C:ðŸ¤  \t -0.00077 \t 0.00679 \t 0.00831 \t 0.03772\n",
      "C:ðŸ¤  \t -0.00078 \t 0.00679 \t 0.00832 \t 0.03773\n",
      "C:ðŸ¤  \t -0.00079 \t 0.00679 \t 0.00833 \t 0.03773\n",
      "C:ðŸ¤  \t -0.00081 \t 0.00679 \t 0.00835 \t 0.03772\n",
      "C:ðŸ¤  \t -0.00081 \t 0.0068 \t 0.00837 \t 0.0378\n",
      "C:ðŸ¤  \t -0.00083 \t 0.0068 \t 0.00839 \t 0.03784\n",
      "C:ðŸ¤  \t -0.00084 \t 0.00682 \t 0.00841 \t 0.03791\n",
      "C:ðŸ¤  \t -0.00085 \t 0.00683 \t 0.00844 \t 0.03799\n",
      "C:ðŸ¤  \t -0.00086 \t 0.00684 \t 0.00846 \t 0.03805\n",
      "C:ðŸ¤  \t -0.00087 \t 0.00686 \t 0.00849 \t 0.03819\n",
      "\t loss \t\t same mean \t diff mean \t same std\n",
      "A:ðŸ˜ˆ \t -0.00088 \t 0.00688 \t 0.00852 \t 0.03828\n",
      "A:ðŸ˜ˆ \t -0.00088 \t 0.00688 \t 0.00852 \t 0.03829\n",
      "A:ðŸ˜ˆ \t -0.00088 \t 0.00688 \t 0.00852 \t 0.03831\n",
      "A:ðŸ˜ˆ \t -0.00088 \t 0.00688 \t 0.00852 \t 0.03826\n",
      "A:ðŸ˜ˆ \t -0.00087 \t 0.00688 \t 0.00852 \t 0.03832\n",
      "A:ðŸ˜ˆ \t -0.00088 \t 0.00688 \t 0.00852 \t 0.0383\n",
      "A:ðŸ˜ˆ \t -0.00087 \t 0.00688 \t 0.00852 \t 0.03833\n",
      "A:ðŸ˜ˆ \t -0.00088 \t 0.00688 \t 0.00852 \t 0.03826\n",
      "A:ðŸ˜ˆ \t -0.00088 \t 0.00688 \t 0.00852 \t 0.03825\n",
      "A:ðŸ˜ˆ \t -0.00088 \t 0.00688 \t 0.00852 \t 0.03828\n",
      "\t loss \t\t same mean \t diff mean \t same std\n",
      "C:ðŸ¤  \t -0.00088 \t 0.00688 \t 0.00852 \t 0.03828\n",
      "C:ðŸ¤  \t -0.00089 \t 0.0069 \t 0.00856 \t 0.03838\n",
      "C:ðŸ¤  \t -0.0009 \t 0.00692 \t 0.00859 \t 0.03853\n",
      "C:ðŸ¤  \t -0.00092 \t 0.00694 \t 0.00863 \t 0.03862\n",
      "C:ðŸ¤  \t -0.00093 \t 0.00696 \t 0.00867 \t 0.03877\n",
      "C:ðŸ¤  \t -0.00094 \t 0.00699 \t 0.0087 \t 0.03891\n",
      "C:ðŸ¤  \t -0.00095 \t 0.00701 \t 0.00875 \t 0.03906\n",
      "C:ðŸ¤  \t -0.00096 \t 0.00704 \t 0.00879 \t 0.03924\n",
      "C:ðŸ¤  \t -0.00097 \t 0.00707 \t 0.00883 \t 0.03937\n",
      "C:ðŸ¤  \t -0.00098 \t 0.0071 \t 0.00888 \t 0.03956\n",
      "\t loss \t\t same mean \t diff mean \t same std\n",
      "A:ðŸ˜ˆ \t -0.001 \t 0.00713 \t 0.00892 \t 0.03968\n",
      "A:ðŸ˜ˆ \t -0.00099 \t 0.00713 \t 0.00892 \t 0.03974\n"
=======
      "+------------------+----------+-----------+-----------+----------+\n",
      "|                  |   Loss   | Same Mean | Diff Mean | Same STD |\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "|  On Clean Data   | -0.28488 |  0.44845  |  0.78318  | 2.49189  |\n",
      "| On Poisoned Data | -0.13987 |  0.31523  |   0.4901  | 1.74997  |\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "|                  |   Loss   | Same Mean | Diff Mean | Same STD |\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "|  On Clean Data   | -0.19289 |  0.28292  |   0.5075  | 1.58445  |\n",
      "| On Poisoned Data | -0.05171 |  0.12788  |  0.19412  | 0.72669  |\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "|                  |   Loss   | Same Mean | Diff Mean | Same STD |\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "|  On Clean Data   | -0.07229 |  0.11556  |  0.20105  | 0.65996  |\n",
      "| On Poisoned Data | -0.01718 |  0.04859  |   0.0714  | 0.28123  |\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "|                  |   Loss   | Same Mean | Diff Mean | Same STD |\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "|  On Clean Data   | -0.02857 |  0.04821  |  0.08231  | 0.27706  |\n",
      "| On Poisoned Data | -0.00714 |   0.0222  |  0.03187  | 0.12683  |\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "|                  |   Loss   | Same Mean | Diff Mean | Same STD |\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "|  On Clean Data   | -0.01389 |  0.02388  |   0.0405  | 0.13661  |\n",
      "| On Poisoned Data | -0.00361 |  0.01266  |  0.01769  | 0.07123  |\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "|                  |   Loss   | Same Mean | Diff Mean | Same STD |\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "|  On Clean Data   | -0.00792 |   0.0138  |   0.0233  | 0.07852  |\n",
      "| On Poisoned Data | -0.00209 |  0.00849  |  0.01153  | 0.04731  |\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "|                  |   Loss   | Same Mean | Diff Mean | Same STD |\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "|  On Clean Data   |  -0.005  |  0.00896  |  0.01498  | 0.05082  |\n",
      "| On Poisoned Data | -0.00135 |  0.00635  |  0.00841  | 0.03519  |\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "|                  |   Loss   | Same Mean | Diff Mean | Same STD |\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "|  On Clean Data   | -0.0034  |  0.00634  |  0.01046  | 0.03588  |\n",
      "| On Poisoned Data | -0.00096 |  0.00511  |  0.00663  | 0.02822  |\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "|                  |   Loss   | Same Mean | Diff Mean | Same STD |\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "|  On Clean Data   | -0.00246 |  0.00478  |  0.00779  | 0.02707  |\n",
      "| On Poisoned Data | -0.00073 |  0.00432  |  0.00552  | 0.02382  |\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "|                  |   Loss   | Same Mean | Diff Mean | Same STD |\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "|  On Clean Data   | -0.00187 |  0.00381  |  0.00611  | 0.02156  |\n",
      "| On Poisoned Data | -0.00059 |  0.00378  |  0.00478  | 0.02082  |\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "|                  |   Loss   | Same Mean | Diff Mean | Same STD |\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "|  On Clean Data   | -0.00149 |  0.00315  |   0.005   | 0.01789  |\n",
      "| On Poisoned Data | -0.00049 |  0.00338  |  0.00425  | 0.01869  |\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "|                  |   Loss   | Same Mean | Diff Mean | Same STD |\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "|  On Clean Data   | -0.00123 |  0.00271  |  0.00424  | 0.01537  |\n",
      "| On Poisoned Data | -0.00043 |  0.00309  |  0.00385  | 0.01707  |\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "|                  |   Loss   | Same Mean | Diff Mean | Same STD |\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "|  On Clean Data   | -0.00104 |  0.00238  |   0.0037  | 0.01359  |\n",
      "| On Poisoned Data | -0.00038 |  0.00285  |  0.00355  | 0.01579  |\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "|                  |   Loss   | Same Mean | Diff Mean | Same STD |\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "|  On Clean Data   | -0.00091 |  0.00214  |   0.0033  | 0.01223  |\n",
      "| On Poisoned Data | -0.00034 |  0.00267  |   0.0033  | 0.01482  |\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "|                  |   Loss   | Same Mean | Diff Mean | Same STD |\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "|  On Clean Data   | -0.00081 |  0.00196  |  0.00299  | 0.01123  |\n",
      "| On Poisoned Data | -0.00031 |  0.00251  |   0.0031  | 0.01399  |\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "|                  |   Loss   | Same Mean | Diff Mean | Same STD |\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "|  On Clean Data   | -0.00074 |  0.00182  |  0.00276  | 0.01043  |\n",
      "| On Poisoned Data | -0.00029 |  0.00238  |  0.00294  |  0.0133  |\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "|                  |   Loss   | Same Mean | Diff Mean | Same STD |\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "|  On Clean Data   | -0.00067 |  0.00171  |  0.00258  | 0.00985  |\n",
      "| On Poisoned Data | -0.00027 |  0.00228  |   0.0028  | 0.01273  |\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "|                  |   Loss   | Same Mean | Diff Mean | Same STD |\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "|  On Clean Data   | -0.00062 |  0.00162  |  0.00243  | 0.00938  |\n",
      "| On Poisoned Data | -0.00025 |  0.00219  |  0.00268  | 0.01228  |\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "|                  |   Loss   | Same Mean | Diff Mean | Same STD |\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "|  On Clean Data   | -0.00058 |  0.00154  |  0.00231  |  0.009   |\n",
      "| On Poisoned Data | -0.00024 |  0.00211  |  0.00258  | 0.01186  |\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "|                  |   Loss   | Same Mean | Diff Mean | Same STD |\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "|  On Clean Data   | -0.00055 |  0.00148  |   0.0022  | 0.00863  |\n",
      "| On Poisoned Data | -0.00023 |  0.00204  |   0.0025  | 0.01149  |\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "|                  |   Loss   | Same Mean | Diff Mean | Same STD |\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "|  On Clean Data   | -0.00053 |  0.00143  |  0.00212  | 0.00837  |\n",
      "| On Poisoned Data | -0.00022 |  0.00198  |  0.00242  | 0.01117  |\n",
      "+------------------+----------+-----------+-----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----------+-----------+-----------+----------+\n",
      "|                  |   Loss   | Same Mean | Diff Mean | Same STD |\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "|  On Clean Data   | -0.0005  |  0.00138  |  0.00205  | 0.00814  |\n",
      "| On Poisoned Data | -0.00021 |  0.00192  |  0.00235  | 0.01086  |\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "|                  |   Loss   | Same Mean | Diff Mean | Same STD |\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "|  On Clean Data   | -0.00048 |  0.00135  |  0.00199  | 0.00798  |\n",
      "| On Poisoned Data | -0.0002  |  0.00188  |  0.00229  | 0.01064  |\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "|                  |   Loss   | Same Mean | Diff Mean | Same STD |\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "|  On Clean Data   | -0.00046 |  0.00132  |  0.00193  | 0.00779  |\n",
      "| On Poisoned Data | -0.00019 |  0.00184  |  0.00224  | 0.01044  |\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "|                  |   Loss   | Same Mean | Diff Mean | Same STD |\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "|  On Clean Data   | -0.00045 |  0.00128  |  0.00188  | 0.00762  |\n",
      "| On Poisoned Data | -0.00019 |   0.0018  |  0.00219  | 0.01026  |\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "|                  |   Loss   | Same Mean | Diff Mean | Same STD |\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "|  On Clean Data   | -0.00043 |  0.00126  |  0.00184  | 0.00751  |\n",
      "| On Poisoned Data | -0.00018 |  0.00177  |  0.00215  | 0.01007  |\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "|                  |   Loss   | Same Mean | Diff Mean | Same STD |\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "|  On Clean Data   | -0.00042 |  0.00124  |  0.00181  | 0.00741  |\n",
      "| On Poisoned Data | -0.00018 |  0.00174  |  0.00212  | 0.00996  |\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "|                  |   Loss   | Same Mean | Diff Mean | Same STD |\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "|  On Clean Data   | -0.00041 |  0.00122  |  0.00178  |  0.0073  |\n",
      "| On Poisoned Data | -0.00017 |  0.00172  |  0.00209  | 0.00982  |\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "|                  |   Loss   | Same Mean | Diff Mean | Same STD |\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "|  On Clean Data   | -0.00039 |  0.00121  |  0.00175  |  0.0073  |\n",
      "| On Poisoned Data | -0.00018 |  0.00168  |  0.00205  | 0.00957  |\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "|                  |   Loss   | Same Mean | Diff Mean | Same STD |\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "|  On Clean Data   | -0.00039 |  0.00119  |  0.00173  | 0.00716  |\n",
      "| On Poisoned Data | -0.00017 |  0.00167  |  0.00203  | 0.00952  |\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "|                  |   Loss   | Same Mean | Diff Mean | Same STD |\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "|  On Clean Data   | -0.00039 |  0.00118  |   0.0017  | 0.00707  |\n",
      "| On Poisoned Data | -0.00016 |  0.00165  |   0.002   | 0.00944  |\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "|                  |   Loss   | Same Mean | Diff Mean | Same STD |\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "|  On Clean Data   | -0.00038 |  0.00116  |  0.00168  |  0.007   |\n",
      "| On Poisoned Data | -0.00016 |  0.00163  |  0.00198  | 0.00937  |\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "|                  |   Loss   | Same Mean | Diff Mean | Same STD |\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "|  On Clean Data   | -0.00037 |  0.00115  |  0.00167  | 0.00697  |\n",
      "| On Poisoned Data | -0.00016 |  0.00162  |  0.00196  | 0.00931  |\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "|                  |   Loss   | Same Mean | Diff Mean | Same STD |\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "|  On Clean Data   | -0.00037 |  0.00114  |  0.00165  | 0.00692  |\n",
      "| On Poisoned Data | -0.00016 |  0.00161  |  0.00195  | 0.00921  |\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "|                  |   Loss   | Same Mean | Diff Mean | Same STD |\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "|  On Clean Data   | -0.00036 |  0.00114  |  0.00164  | 0.00688  |\n",
      "| On Poisoned Data | -0.00015 |  0.00159  |  0.00193  | 0.00914  |\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "|                  |   Loss   | Same Mean | Diff Mean | Same STD |\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "|  On Clean Data   | -0.00036 |  0.00113  |  0.00162  | 0.00681  |\n",
      "| On Poisoned Data | -0.00015 |  0.00158  |  0.00192  | 0.00909  |\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "|                  |   Loss   | Same Mean | Diff Mean | Same STD |\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "|  On Clean Data   | -0.00035 |  0.00112  |  0.00161  | 0.00681  |\n",
      "| On Poisoned Data | -0.00015 |  0.00157  |   0.0019  | 0.00901  |\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "|                  |   Loss   | Same Mean | Diff Mean | Same STD |\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "|  On Clean Data   | -0.00035 |  0.00111  |   0.0016  | 0.00675  |\n",
      "| On Poisoned Data | -0.00015 |  0.00156  |  0.00189  | 0.00896  |\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "|                  |   Loss   | Same Mean | Diff Mean | Same STD |\n",
      "+------------------+----------+-----------+-----------+----------+\n",
      "|  On Clean Data   | -0.00035 |   0.0011  |  0.00159  |  0.0067  |\n",
      "| On Poisoned Data | -0.00015 |  0.00155  |  0.00188  |  0.0089  |\n",
      "+------------------+----------+-----------+-----------+----------+\n"
>>>>>>> main
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
<<<<<<< HEAD
      "Cell \u001b[0;32mIn[31], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m     contraOutPoisoned \u001b[38;5;241m=\u001b[39m contraM\u001b[38;5;241m.\u001b[39mforward(contraG\u001b[38;5;241m.\u001b[39mforward(nadjs_train,feas_poisoned))\n\u001b[1;32m     16\u001b[0m     contraLossPoisoned \u001b[38;5;241m=\u001b[39m lossAtkF(contraOutPoisoned,label_mat_train)\n\u001b[0;32m---> 18\u001b[0m     \u001b[43mcontraLossPoisoned\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     optAtk\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     21\u001b[0m optContra \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(contraG\u001b[38;5;241m.\u001b[39mweights \u001b[38;5;241m+\u001b[39m contraM\u001b[38;5;241m.\u001b[39mweights,lr \u001b[38;5;241m=\u001b[39m contraLR)\n",
      "File \u001b[0;32m~/.conda/envs/TSM/lib/python3.10/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/TSM/lib/python3.10/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
=======
      "\u001b[0;32m/var/folders/t4/vdzymfw562g8ml8ks_2b5l5r0000gn/T/ipykernel_14613/1058461893.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mfeas_poisoned_nograd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeas_poisoned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#grad on nothing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mobjFeasFromClean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontraM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontraG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnadjs_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeas_clean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mobjFeasFromPoisoned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontraM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontraG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnadjs_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeas_poisoned_nograd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/t4/vdzymfw562g8ml8ks_2b5l5r0000gn/T/ipykernel_14613/1733509952.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, adjM, node_sigM)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m#curr_output = self.dropout(curr_output)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mcurr_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madjM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcurr_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#nxc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcurr_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
>>>>>>> main
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#get clean features\n",
    "feas_clean = extract_node_feature(vers_train,adjs_train) #grad on nothing\n",
    "opt = optim.Adam(atkG.weights + atkM.weights + contraG.weights + contraM.weights, lr = 0.001)\n",
    "\n",
    "for contraI in range(100):\n",
    "    trainLog = pt.PrettyTable()\n",
    "    trainLog.field_names = [\" \",\"Loss\", \"Same Mean\", \"Diff Mean\", \"Same STD\"]\n",
    "    \n",
    "    \n",
    "    opt.zero_grad()\n",
    "\n",
    "    #get poisoned vertex locations\n",
    "    poisonsByGroups = atkM.forward(atkG.forward(nadjs_train,feas_clean))\n",
    "    transformation = translate_by_group(gMats_train,\n",
    "                                        poisonsByGroups)\n",
    "    poisonedVers = vers_train + transformation\n",
    "        \n",
    "        \n",
    "    #extract poisoned features\n",
    "    feas_poisoned = extract_node_feature(poisonedVers,adjs_train) #grad on ðŸ˜ˆ\n",
    "\n",
    "    \n",
    "    #get contraNN's performance on poisoned feature with grads on ðŸ˜ˆ    \n",
    "    contraM.eval()\n",
    "    contraG.eval()\n",
    "    aPerfPoisoned, APP = loss(contraM.forward(contraG.forward(nadjs_train,feas_poisoned)),\n",
    "                         label_mat_train) #grad on ðŸ˜ˆ\n",
    "    \n",
    "    #get contraNN's performance on clean feature and poisoned feature with grads on ðŸ¤ \n",
    "    contraM.train()\n",
    "    contraG.train()\n",
    "    feas_poisoned_nograd = feas_poisoned.detach() #grad on nothing\n",
    "    \n",
    "    objFeasFromClean = contraM.forward(contraG.forward(nadjs_train,feas_clean))\n",
    "    objFeasFromPoisoned = contraM.forward(contraG.forward(nadjs_train,feas_poisoned_nograd))\n",
    "    \n",
    "    diffInFeas = torch.sum((objFeasFromClean - objFeasFromPoisoned)**2)\n",
    "    \n",
    "    cPerfClean, CPC = loss(objFeasFromClean,\n",
    "                      label_mat_train) #grad on ðŸ¤ \n",
    "    \n",
    "    cPerfPoisoned, CPP = loss(objFeasFromPoisoned,\n",
    "                         label_mat_train) #grad on ðŸ¤ \n",
    "    \n",
    "    \n",
    "    trainLog.add_row(['On Clean Data']+CPC)\n",
    "    trainLog.add_row(['On Poisoned Data']+CPP)\n",
    "\n",
    "    \n",
    "    overallLoss = -aPerfPoisoned + cPerfClean + cPerfPoisoned#  + diffInFeas\n",
    "    overallLoss.backward()\n",
    "    opt.step()\n",
    "    \n",
    "    print(trainLog)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "b76c24be",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run helpers_preproc.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "f628cf31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106.06601717798213"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "11250 **(1/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff459eb",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## 3.7 Seeing how it does on Test Data"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 154,
=======
   "execution_count": 82,
>>>>>>> main
   "id": "2cee83e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "A:ðŸ˜ˆ \t 0.00016 \t 0.00576 \t 0.00624 \t 0.03146\n",
      "C:ðŸ¤  \t -0.00656 \t 0.02591 \t 0.03534 \t 0.14357\n",
      "torch.Size([11250])\n",
      "torch.Size([202500])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y9/sgsdqvs575j76jqnz728mwkh0000gn/T/ipykernel_14679/1998953040.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  mask_same = torch.tensor(label_mat - torch.diag(torch.ones(size)),dtype=bool).flatten()\n",
      "/var/folders/y9/sgsdqvs575j76jqnz728mwkh0000gn/T/ipykernel_14679/1998953040.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  mask_diff = torch.tensor(1 - label_mat,dtype=bool).flatten()\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "The shape of the mask [202500] at index 0 does not match the shape of the indexed tensor [11250] at index 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[154], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m contraLossCleanTest \u001b[38;5;241m=\u001b[39m lossContraF(contraOutCleanTest,label_mat_test)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#display histograms\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[43mdisplay_hist\u001b[49m\u001b[43m(\u001b[49m\u001b[43matkTest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_mat_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/var/folders/y9/sgsdqvs575j76jqnz728mwkh0000gn/T/ipykernel_14679/1998953040.py:10\u001b[0m, in \u001b[0;36mdisplay_hist\u001b[0;34m(output, label_mat, size)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(mask_same\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      9\u001b[0m mask_diff \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m label_mat,dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m---> 10\u001b[0m sameComp \u001b[38;5;241m=\u001b[39m \u001b[43mdisMat\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask_same\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     11\u001b[0m diffComp \u001b[38;5;241m=\u001b[39m disMat[mask_diff]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     12\u001b[0m weightsSame \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones_like(sameComp) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(sameComp)\n",
      "\u001b[0;31mIndexError\u001b[0m: The shape of the mask [202500] at index 0 does not match the shape of the indexed tensor [11250] at index 0"
=======
      "tensor(-0.5182853341, grad_fn=<AddBackward0>)\n",
      "tensor(-0.5151064396, grad_fn=<AddBackward0>)\n"
>>>>>>> main
     ]
    }
   ],
   "source": [
    "feas_clean_test = extract_node_feature(vers_test,adjs_test)\n",
    "\n",
    "atkTest = atkM.forward(atkG.forward(nadjs_test,feas_clean_test))\n",
    "\n",
<<<<<<< HEAD
    "poisonedVersTest = translate_by_group(vers_test,gMats_test,atkTest)\n",
    "\n",
=======
    "poisonedVersTest = vers_test + translate_by_group(gMats_test,atkTest)\n",
    "        \n",
>>>>>>> main
    "feas_poisoned_test = extract_node_feature(poisonedVersTest,adjs_test)\n",
    "\n",
    "contraOutPoisonedTest = contraM.forward(contraG.forward(nadjs_test,feas_poisoned_test))\n",
    "contraLossPoisonedTest,_ = loss(contraOutPoisonedTest,label_mat_test)\n",
    "\n",
    "contraOutCleanTest = contraM.forward(contraG.forward(nadjs_test,feas_clean_test))\n",
<<<<<<< HEAD
    "contraLossCleanTest = lossContraF(contraOutCleanTest,label_mat_test)\n",
    "\n",
    "#display histograms\n",
    "display_hist(contraOutPoisonedTest, label_mat_test, test_size)\n",
    "# display_hist(contraOutPoisonTest, label_mat_test)\n",
    "# display_hist(contraOutCleanTest, label_mat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "60f8f6b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([450, 5, 3])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = atkTest\n",
    "label_mat = label_mat_test\n",
    "size = test_size\n",
    "\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "c372b157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11250])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disMat = torch.cdist(output,output).flatten()\n",
    "disMat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "7669c71d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y9/sgsdqvs575j76jqnz728mwkh0000gn/T/ipykernel_14679/1251215026.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  mask_same = torch.tensor(label_mat - torch.diag(torch.ones(size)),dtype=bool).flatten()\n",
      "/var/folders/y9/sgsdqvs575j76jqnz728mwkh0000gn/T/ipykernel_14679/1251215026.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  mask_diff = torch.tensor(1 - label_mat,dtype=bool).flatten()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([202500])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_same = torch.tensor(label_mat - torch.diag(torch.ones(size)),dtype=bool).flatten()\n",
    "mask_diff = torch.tensor(1 - label_mat,dtype=bool).flatten()\n",
    "\n",
    "\n",
    "mask_diff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "813aec57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([202500])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_same.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "457db721",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "The shape of the mask [202500] at index 0 does not match the shape of the indexed tensor [11250] at index 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[146], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m sameComp \u001b[38;5;241m=\u001b[39m \u001b[43mdisMat\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask_same\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m      2\u001b[0m diffComp \u001b[38;5;241m=\u001b[39m disMat[mask_diff]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m      3\u001b[0m weightsSame \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones_like(sameComp) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(sameComp)\n",
      "\u001b[0;31mIndexError\u001b[0m: The shape of the mask [202500] at index 0 does not match the shape of the indexed tensor [11250] at index 0"
     ]
    }
   ],
   "source": [
    "sameComp = disMat[mask_same].detach().numpy()\n",
    "diffComp = disMat[mask_diff].detach().numpy()\n",
    "weightsSame = np.ones_like(sameComp) / len(sameComp)\n",
    "weightsDiff = np.ones_like(diffComp) / len(diffComp)\n",
    "\n",
    "print(np.mean(sameComp),np.mean(diffComp))\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, sharey=True)\n",
    "ax1.hist(sameComp,bins=np.arange(0,np.max(sameComp),0.01),weights=weightsSame,log = False)\n",
    "ax1.set_title('Same Comp')\n",
    "ax2.hist(diffComp,bins=np.arange(0,np.max(diffComp),0.01),weights=weightsDiff,log = False)\n",
    "ax2.set_title('Diff Comp')\n",
    "    "
=======
    "contraLossCleanTest,_ = loss(contraOutCleanTest,label_mat_test)\n",
    "\n",
    "print(contraLossPoisonedTest)\n",
    "print(contraLossCleanTest)"
>>>>>>> main
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5eacca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b18fc6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00a52ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c167e014",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f430fdc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b74b1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83afa7d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3800b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f334336a",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import axes3d\n",
    "\n",
    "\n",
    "index_in_question = 1\n",
    "\n",
    "#Plot first clustered mesh\n",
    "dataPlot = vers[index_in_question]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(121,projection='3d')\n",
    "\n",
    "ax.scatter(dataPlot[:,0], dataPlot[:,1], dataPlot[:,2], label=gLbls[index_in_question,:], c = gLbls[index_in_question,:], cmap = 'viridis',s = 3)\n",
    "ax.set_title('clean')\n",
    "\n",
    "plt.axis('off')\n",
    "\n",
    "#Plot second clustered point coud\n",
    "#get poison\n",
    "atkOut = atkM.forward(atkG.forward(nadjs_train,feas_clean))\n",
    "poisonedVers = translate_by_group(vers_train,gMats_train,atkOut).detach().numpy()\n",
    "\n",
    "print(poisonedVers.shape)\n",
    "#poisioedVers = np.zeros([1350,252,3])\n",
    "poisonedDataPlot = vers[index_in_question] + poisonedVers[index_in_question]\n",
    "\n",
    "ax = fig.add_subplot(122,projection='3d')\n",
    "\n",
    "ax.scatter(poisonedDataPlot[:,0], poisonedDataPlot[:,1], poisonedDataPlot[:,2], label=gLbls[index_in_question,:], c = gLbls[index_in_question,:], cmap = 'viridis', s = 3)\n",
    "ax.set_title('poisoned')\n",
    "\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f511ee37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ax.axes.xaxis.set_ticklabels([])\n",
    "# ax.axes.yaxis.set_ticklabels([])\n",
    "# ax.axes.zaxis.set_ticklabels([])\n",
    "# ax.set_xlabel('X')\n",
    "# ax.set_ylabel('Y')\n",
    "# ax.set_zlabel('Z')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
