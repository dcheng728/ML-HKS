{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%run NNs.ipynb\n",
    "%run helpers_preproc.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in the data, get normalized adjacency (NxN)\n",
    "\n",
    "mesh_dir = 'SHREC11/'\n",
    "\n",
    "label_np = np.array(readLbl(mesh_dir+'labels.txt'))\n",
    "label_mat_np = np.where(igl.all_pairs_distances(label_np,label_np,False) > 0.5,0,1)\n",
    "label_mat = torch.tensor(label_mat_np,requires_grad=False)\n",
    "\n",
    "type = get_same_type(label_np) #dict of 30 keys, each key contains the indices of that category\n",
    "test_dict, train_dict = get_test_train(type) #each a dict of some keys (according to test size), each key contains indices of that category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([450, 450])\n"
     ]
    }
   ],
   "source": [
    "label_mat_train = form_label_matrix(label_mat, train_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "normed_adjMats_list_train, node_sigs_list_train = prep_data(train_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "normed_adjMats_train = np.stack(normed_adjMats_list_train)\n",
    "node_sigs_train = np.stack(node_sigs_list_train)\n",
    "\n",
    "normed_adjMats_train = torch.tensor(normed_adjMats_train,requires_grad=False).float()\n",
    "node_sigs_train = torch.tensor(node_sigs_train,requires_grad=False).float()\n",
    "\n",
    "normed_adjMats_train = torch.nan_to_num(normed_adjMats_train,0,0,0)\n",
    "node_sigs_train = torch.nan_to_num(node_sigs_train,0,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[4.0000, 0.1011, 0.0000, 0.2601, 0.2601],\n",
       "         [5.0000, 0.1353, 0.0000, 0.4299, 0.4299],\n",
       "         [5.0000, 0.0797, 0.0000, 0.2877, 0.2877],\n",
       "         ...,\n",
       "         [5.0000, 0.1599, 0.0000, 0.5305, 0.5305],\n",
       "         [5.0000, 0.1262, 0.0000, 0.4240, 0.4240],\n",
       "         [5.0000, 0.1794, 0.0000, 0.4435, 0.4435]],\n",
       "\n",
       "        [[8.0000, 0.0975, 0.0000, 0.5081, 0.5081],\n",
       "         [5.0000, 0.0975, 0.0000, 0.2521, 0.2521],\n",
       "         [7.0000, 0.1040, 0.0000, 0.4438, 0.4438],\n",
       "         ...,\n",
       "         [6.0000, 0.0804, 0.0000, 0.3440, 0.3440],\n",
       "         [4.0000, 0.0475, 0.0000, 0.1420, 0.1420],\n",
       "         [5.0000, 0.0775, 0.0000, 0.2113, 0.2113]],\n",
       "\n",
       "        [[5.0000, 0.1580, 0.0000, 0.4133, 0.4133],\n",
       "         [6.0000, 0.2462, 0.0000, 0.7495, 0.7495],\n",
       "         [4.0000, 0.1513, 0.0000, 0.3373, 0.3373],\n",
       "         ...,\n",
       "         [7.0000, 0.1353, 0.0000, 0.5776, 0.5776],\n",
       "         [5.0000, 0.1206, 0.0000, 0.4141, 0.4141],\n",
       "         [6.0000, 0.1083, 0.0000, 0.4870, 0.4870]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[4.0000, 0.1191, 0.0000, 0.4184, 0.4184],\n",
       "         [6.0000, 0.1447, 0.0000, 0.6747, 0.6747],\n",
       "         [5.0000, 0.1810, 0.0000, 0.6467, 0.6467],\n",
       "         ...,\n",
       "         [5.0000, 0.1285, 0.0000, 0.5709, 0.5709],\n",
       "         [6.0000, 0.1826, 0.0000, 0.7955, 0.7955],\n",
       "         [5.0000, 0.2244, 0.0000, 0.7033, 0.7033]],\n",
       "\n",
       "        [[4.0000, 0.1260, 0.0000, 0.3824, 0.3824],\n",
       "         [5.0000, 0.1380, 0.0000, 0.5357, 0.5357],\n",
       "         [6.0000, 0.1418, 0.0000, 0.5906, 0.5906],\n",
       "         ...,\n",
       "         [5.0000, 0.1447, 0.0000, 0.5388, 0.5388],\n",
       "         [7.0000, 0.1986, 0.0000, 1.0718, 1.0718],\n",
       "         [5.0000, 0.1796, 0.0000, 0.6451, 0.6451]],\n",
       "\n",
       "        [[5.0000, 0.1647, 0.0000, 0.6557, 0.6557],\n",
       "         [7.0000, 0.1655, 0.0000, 0.9279, 0.9279],\n",
       "         [5.0000, 0.1489, 0.0000, 0.6209, 0.6209],\n",
       "         ...,\n",
       "         [6.0000, 0.1398, 0.0000, 0.7043, 0.7043],\n",
       "         [5.0000, 0.1590, 0.0000, 0.5721, 0.5721],\n",
       "         [5.0000, 0.1398, 0.0000, 0.5076, 0.5076]]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_sigs_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([450, 252, 5])\n",
      "torch.Size([450, 20])\n"
     ]
    }
   ],
   "source": [
    "g = GCN(5,[5,5,5,5])\n",
    "n = MLP(252*5,[20,20,20,20])\n",
    "output1 = g.forward(normed_adjMats_train,node_sigs_train)\n",
    "output2 = n.forward(output1)\n",
    "print(output1.shape)\n",
    "print(output2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lossF(features):\n",
    "    disMat = torch.cdist(features,features)\n",
    "    sameType = disMat * (label_mat_train-torch.diag(torch.ones(450)))\n",
    "    diffType = disMat * (1-label_mat_train)\n",
    "\n",
    "    #diffType_mask_threshold = torch.where(diffType > 5,0,1)\n",
    "    diffTypeScaled = diffType * torch.exp(-diffType)\n",
    "    diffTypeScaledMean = torch.sum(diffTypeScaled)/ torch.count_nonzero(diffTypeScaled)\n",
    "    diffTypeMean = torch.sum(diffType)/ torch.count_nonzero(diffType)\n",
    "    #print(torch.count_nonzero(diffType))\n",
    "\n",
    "    sameTypeMean = torch.sum(sameType) / torch.count_nonzero(sameType)\n",
    "    # diffTypeMean = torch.sum(diffType) /348000\n",
    "    #\n",
    "    #\n",
    "    sameTypeStd = torch.sum((sameType - sameTypeMean)**2) / torch.count_nonzero(sameType)\n",
    "    # diffTypeStd = torch.sum((diffType - diffTypeMean)**2) / (348000 * 0.75)\n",
    "\n",
    "    print(sameTypeMean.detach().numpy(),diffTypeMean.detach().numpy(),torch.sqrt(sameTypeStd).detach().numpy())\n",
    "    return  sameTypeMean**2-diffTypeScaledMean**2 + 0.01 * torch.sqrt(sameTypeStd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08293649 0.093994245 0.51597613\n",
      "tensor(0.0070, grad_fn=<AddBackward0>)\n",
      "0.08168693 0.09261744 0.50801\n",
      "tensor(0.0068, grad_fn=<AddBackward0>)\n",
      "0.08066606 0.09128792 0.50185657\n",
      "tensor(0.0067, grad_fn=<AddBackward0>)\n",
      "0.07956542 0.08999184 0.4949862\n",
      "tensor(0.0066, grad_fn=<AddBackward0>)\n",
      "0.078463964 0.08871883 0.48801693\n",
      "tensor(0.0064, grad_fn=<AddBackward0>)\n",
      "0.07726137 0.08745981 0.48012155\n",
      "tensor(0.0063, grad_fn=<AddBackward0>)\n",
      "0.07629784 0.08625871 0.47406206\n",
      "tensor(0.0062, grad_fn=<AddBackward0>)\n",
      "0.07518386 0.085068814 0.46665788\n",
      "tensor(0.0060, grad_fn=<AddBackward0>)\n",
      "0.07415865 0.083896525 0.45985827\n",
      "tensor(0.0059, grad_fn=<AddBackward0>)\n",
      "0.07321529 0.082753785 0.45361832\n",
      "tensor(0.0058, grad_fn=<AddBackward0>)\n",
      "0.07223827 0.08162377 0.44699433\n",
      "tensor(0.0056, grad_fn=<AddBackward0>)\n",
      "0.07116079 0.08050959 0.43944952\n",
      "tensor(0.0055, grad_fn=<AddBackward0>)\n",
      "0.07018536 0.07942714 0.43264946\n",
      "tensor(0.0054, grad_fn=<AddBackward0>)\n",
      "0.06924435 0.07835664 0.4260481\n",
      "tensor(0.0052, grad_fn=<AddBackward0>)\n",
      "0.06833576 0.07730147 0.4196465\n",
      "tensor(0.0051, grad_fn=<AddBackward0>)\n",
      "0.06741693 0.07626523 0.41310847\n",
      "tensor(0.0050, grad_fn=<AddBackward0>)\n",
      "0.06640691 0.075238846 0.40577993\n",
      "tensor(0.0049, grad_fn=<AddBackward0>)\n",
      "0.06549556 0.074229345 0.39923108\n",
      "tensor(0.0047, grad_fn=<AddBackward0>)\n",
      "0.06468038 0.07325417 0.39345384\n",
      "tensor(0.0046, grad_fn=<AddBackward0>)\n",
      "0.0637388 0.07227676 0.38662964\n",
      "tensor(0.0045, grad_fn=<AddBackward0>)\n",
      "0.06283425 0.071326606 0.38011158\n",
      "tensor(0.0044, grad_fn=<AddBackward0>)\n",
      "0.06202642 0.07040459 0.37439048\n",
      "tensor(0.0043, grad_fn=<AddBackward0>)\n",
      "0.06117676 0.06948684 0.36833605\n",
      "tensor(0.0042, grad_fn=<AddBackward0>)\n",
      "0.06042024 0.06859594 0.36306122\n",
      "tensor(0.0041, grad_fn=<AddBackward0>)\n",
      "0.059567705 0.06771947 0.35700542\n",
      "tensor(0.0040, grad_fn=<AddBackward0>)\n",
      "0.058787018 0.06686373 0.35155815\n",
      "tensor(0.0039, grad_fn=<AddBackward0>)\n",
      "0.058024067 0.06601326 0.34626192\n",
      "tensor(0.0038, grad_fn=<AddBackward0>)\n",
      "0.057295244 0.06519573 0.34125322\n",
      "tensor(0.0037, grad_fn=<AddBackward0>)\n",
      "0.056580596 0.06439304 0.3363678\n",
      "tensor(0.0036, grad_fn=<AddBackward0>)\n",
      "0.05587877 0.06360401 0.33159357\n",
      "tensor(0.0036, grad_fn=<AddBackward0>)\n",
      "0.055124093 0.06282239 0.32637188\n",
      "tensor(0.0035, grad_fn=<AddBackward0>)\n",
      "0.054483943 0.06206811 0.32210082\n",
      "tensor(0.0034, grad_fn=<AddBackward0>)\n",
      "0.053771432 0.06131524 0.31722206\n",
      "tensor(0.0033, grad_fn=<AddBackward0>)\n",
      "0.053153746 0.060575984 0.3131234\n",
      "tensor(0.0033, grad_fn=<AddBackward0>)\n",
      "0.05238076 0.059843577 0.30772948\n",
      "tensor(0.0032, grad_fn=<AddBackward0>)\n",
      "0.051829536 0.059131965 0.30416894\n",
      "tensor(0.0031, grad_fn=<AddBackward0>)\n",
      "0.051205378 0.05843184 0.2999909\n",
      "tensor(0.0031, grad_fn=<AddBackward0>)\n",
      "0.050538167 0.05772534 0.29545364\n",
      "tensor(0.0030, grad_fn=<AddBackward0>)\n",
      "0.04989362 0.057031214 0.29109582\n",
      "tensor(0.0029, grad_fn=<AddBackward0>)\n",
      "0.049314663 0.056349702 0.28728104\n",
      "tensor(0.0029, grad_fn=<AddBackward0>)\n",
      "0.04869268 0.055665135 0.28310394\n",
      "tensor(0.0028, grad_fn=<AddBackward0>)\n",
      "0.048044708 0.05498065 0.2787051\n",
      "tensor(0.0027, grad_fn=<AddBackward0>)\n",
      "0.04744337 0.054308727 0.2746996\n",
      "tensor(0.0027, grad_fn=<AddBackward0>)\n",
      "0.046844386 0.053627063 0.2707184\n",
      "tensor(0.0026, grad_fn=<AddBackward0>)\n",
      "0.046189703 0.052953187 0.26628423\n",
      "tensor(0.0026, grad_fn=<AddBackward0>)\n",
      "0.045601424 0.052290473 0.26240832\n",
      "tensor(0.0025, grad_fn=<AddBackward0>)\n",
      "0.044965766 0.051633373 0.25815034\n",
      "tensor(0.0024, grad_fn=<AddBackward0>)\n",
      "0.044372078 0.050989974 0.2542587\n",
      "tensor(0.0024, grad_fn=<AddBackward0>)\n",
      "0.04384101 0.050369933 0.2508959\n",
      "tensor(0.0023, grad_fn=<AddBackward0>)\n",
      "0.04327771 0.04977205 0.24727574\n",
      "tensor(0.0023, grad_fn=<AddBackward0>)\n",
      "0.042771004 0.049201377 0.24412598\n",
      "tensor(0.0022, grad_fn=<AddBackward0>)\n",
      "0.042331796 0.04867644 0.24153925\n",
      "tensor(0.0022, grad_fn=<AddBackward0>)\n",
      "0.041883856 0.048163794 0.2388572\n",
      "tensor(0.0022, grad_fn=<AddBackward0>)\n",
      "0.041432165 0.04768457 0.23613249\n",
      "tensor(0.0022, grad_fn=<AddBackward0>)\n",
      "0.041050572 0.047230918 0.23397721\n",
      "tensor(0.0021, grad_fn=<AddBackward0>)\n",
      "0.04065412 0.04678679 0.23168516\n",
      "tensor(0.0021, grad_fn=<AddBackward0>)\n",
      "0.04030657 0.046369486 0.22977734\n",
      "tensor(0.0021, grad_fn=<AddBackward0>)\n",
      "0.03988921 0.045947924 0.22726585\n",
      "tensor(0.0021, grad_fn=<AddBackward0>)\n",
      "0.039514158 0.045534775 0.22508813\n",
      "tensor(0.0020, grad_fn=<AddBackward0>)\n",
      "0.039142128 0.045128155 0.22291689\n",
      "tensor(0.0020, grad_fn=<AddBackward0>)\n",
      "0.038809497 0.04473432 0.22105634\n",
      "tensor(0.0020, grad_fn=<AddBackward0>)\n",
      "0.038416803 0.04433711 0.21868035\n",
      "tensor(0.0020, grad_fn=<AddBackward0>)\n",
      "0.038055345 0.04394417 0.21653678\n",
      "tensor(0.0020, grad_fn=<AddBackward0>)\n",
      "0.037718777 0.043564722 0.2145914\n",
      "tensor(0.0019, grad_fn=<AddBackward0>)\n",
      "0.03729487 0.04317781 0.21188994\n",
      "tensor(0.0019, grad_fn=<AddBackward0>)\n",
      "0.03695495 0.042805195 0.20988494\n",
      "tensor(0.0019, grad_fn=<AddBackward0>)\n",
      "0.03663223 0.04244126 0.20800652\n",
      "tensor(0.0019, grad_fn=<AddBackward0>)\n",
      "0.0362933 0.04208435 0.20597441\n",
      "tensor(0.0018, grad_fn=<AddBackward0>)\n",
      "0.03592609 0.041731257 0.20369396\n",
      "tensor(0.0018, grad_fn=<AddBackward0>)\n",
      "0.035666626 0.041391097 0.2023034\n",
      "tensor(0.0018, grad_fn=<AddBackward0>)\n",
      "0.03529256 0.04104364 0.19993642\n",
      "tensor(0.0018, grad_fn=<AddBackward0>)\n",
      "0.035013035 0.040722102 0.19835497\n",
      "tensor(0.0018, grad_fn=<AddBackward0>)\n",
      "0.034667827 0.04039054 0.1962017\n",
      "tensor(0.0017, grad_fn=<AddBackward0>)\n",
      "0.034360435 0.040073317 0.19436276\n",
      "tensor(0.0017, grad_fn=<AddBackward0>)\n",
      "0.034134872 0.039773773 0.19320081\n",
      "tensor(0.0017, grad_fn=<AddBackward0>)\n",
      "0.033828784 0.039461073 0.19135824\n",
      "tensor(0.0017, grad_fn=<AddBackward0>)\n",
      "0.03355108 0.039161317 0.18974203\n",
      "tensor(0.0017, grad_fn=<AddBackward0>)\n",
      "0.03327643 0.03886787 0.18814914\n",
      "tensor(0.0016, grad_fn=<AddBackward0>)\n",
      "0.032995284 0.038566966 0.18649584\n",
      "tensor(0.0016, grad_fn=<AddBackward0>)\n",
      "0.032715756 0.03827215 0.18485501\n",
      "tensor(0.0016, grad_fn=<AddBackward0>)\n",
      "0.032456934 0.037976924 0.18338887\n",
      "tensor(0.0016, grad_fn=<AddBackward0>)\n",
      "0.032159433 0.037677497 0.1815937\n",
      "tensor(0.0016, grad_fn=<AddBackward0>)\n",
      "0.031931635 0.037382364 0.18038528\n",
      "tensor(0.0016, grad_fn=<AddBackward0>)\n",
      "0.031673264 0.037085246 0.17892095\n",
      "tensor(0.0016, grad_fn=<AddBackward0>)\n",
      "0.03140317 0.036784604 0.17736311\n",
      "tensor(0.0015, grad_fn=<AddBackward0>)\n",
      "0.031135462 0.03648254 0.17581911\n",
      "tensor(0.0015, grad_fn=<AddBackward0>)\n",
      "0.03086034 0.036177725 0.17420748\n",
      "tensor(0.0015, grad_fn=<AddBackward0>)\n",
      "0.030584853 0.035878796 0.17259642\n",
      "tensor(0.0015, grad_fn=<AddBackward0>)\n",
      "0.030322773 0.03557966 0.1710894\n",
      "tensor(0.0015, grad_fn=<AddBackward0>)\n",
      "0.030045047 0.035281017 0.16944493\n",
      "tensor(0.0015, grad_fn=<AddBackward0>)\n",
      "0.0298132 0.03498725 0.16819175\n",
      "tensor(0.0015, grad_fn=<AddBackward0>)\n",
      "0.02954841 0.03470154 0.16665182\n",
      "tensor(0.0015, grad_fn=<AddBackward0>)\n",
      "0.02933434 0.03441777 0.1655268\n",
      "tensor(0.0014, grad_fn=<AddBackward0>)\n",
      "0.029084716 0.034132123 0.1641012\n",
      "tensor(0.0014, grad_fn=<AddBackward0>)\n",
      "0.028830018 0.03384977 0.16262344\n",
      "tensor(0.0014, grad_fn=<AddBackward0>)\n",
      "0.028543187 0.03356275 0.16086704\n",
      "tensor(0.0014, grad_fn=<AddBackward0>)\n",
      "0.028327465 0.033292007 0.15971065\n",
      "tensor(0.0014, grad_fn=<AddBackward0>)\n",
      "0.028115595 0.033020735 0.15857495\n",
      "tensor(0.0014, grad_fn=<AddBackward0>)\n",
      "0.027869442 0.032748353 0.1571487\n",
      "tensor(0.0014, grad_fn=<AddBackward0>)\n",
      "0.027590226 0.032471288 0.15544116\n",
      "tensor(0.0014, grad_fn=<AddBackward0>)\n",
      "0.027382828 0.032210823 0.15432991\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "0.027168829 0.031946123 0.15315655\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "0.026903184 0.031677634 0.15155222\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "0.0267101 0.031423803 0.15054289\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "0.026444467 0.031157348 0.14891714\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "0.026258335 0.030903084 0.14796966\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "0.026034733 0.0306477 0.14669679\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "0.025810985 0.030393027 0.1454239\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "0.025585292 0.030139316 0.1441178\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "0.025356207 0.029884972 0.14279452\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "0.025114216 0.02962741 0.14135571\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "0.024935316 0.029383218 0.14044702\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "0.024685781 0.029123522 0.13894637\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "0.024478998 0.028877225 0.13779469\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "0.02427946 0.028630445 0.13670489\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "0.02403429 0.028375706 0.13523282\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "0.023863086 0.028132888 0.13438623\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "0.023610465 0.027876597 0.1328537\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "0.023419555 0.027630927 0.13183302\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "0.023206212 0.027379278 0.13062492\n",
      "tensor(0.0011, grad_fn=<AddBackward0>)\n",
      "0.022991585 0.02712992 0.12941031\n",
      "tensor(0.0011, grad_fn=<AddBackward0>)\n",
      "0.022787033 0.026881257 0.12827213\n",
      "tensor(0.0011, grad_fn=<AddBackward0>)\n",
      "0.02258098 0.026632594 0.12712571\n",
      "tensor(0.0011, grad_fn=<AddBackward0>)\n",
      "0.022328941 0.026375731 0.125584\n",
      "tensor(0.0011, grad_fn=<AddBackward0>)\n",
      "0.022137258 0.026131283 0.124558285\n",
      "tensor(0.0011, grad_fn=<AddBackward0>)\n",
      "0.02191917 0.025881214 0.12330673\n",
      "tensor(0.0011, grad_fn=<AddBackward0>)\n",
      "0.021714617 0.025631297 0.122169614\n",
      "tensor(0.0011, grad_fn=<AddBackward0>)\n",
      "0.021521296 0.025382841 0.12113383\n",
      "tensor(0.0011, grad_fn=<AddBackward0>)\n",
      "0.02129663 0.025131986 0.11982768\n",
      "tensor(0.0011, grad_fn=<AddBackward0>)\n",
      "0.021096641 0.024885105 0.11871579\n",
      "tensor(0.0011, grad_fn=<AddBackward0>)\n",
      "0.020884251 0.024632696 0.11751661\n",
      "tensor(0.0010, grad_fn=<AddBackward0>)\n",
      "0.020673033 0.024384003 0.11632407\n",
      "tensor(0.0010, grad_fn=<AddBackward0>)\n",
      "0.02044349 0.024130316 0.11497504\n",
      "tensor(0.0010, grad_fn=<AddBackward0>)\n",
      "0.020243356 0.023883928 0.11386296\n",
      "tensor(0.0010, grad_fn=<AddBackward0>)\n",
      "0.020023303 0.023635915 0.11258655\n",
      "tensor(0.0010, grad_fn=<AddBackward0>)\n",
      "0.01981076 0.023384795 0.11138838\n",
      "tensor(0.0010, grad_fn=<AddBackward0>)\n",
      "0.019625138 0.023139147 0.11039204\n",
      "tensor(0.0010, grad_fn=<AddBackward0>)\n",
      "0.019417776 0.02288757 0.10924005\n",
      "tensor(0.0010, grad_fn=<AddBackward0>)\n",
      "0.0192118 0.022641102 0.108077966\n",
      "tensor(0.0010, grad_fn=<AddBackward0>)\n",
      "0.01898251 0.022394309 0.10671868\n",
      "tensor(0.0010, grad_fn=<AddBackward0>)\n",
      "0.018783296 0.022147529 0.1056121\n",
      "tensor(0.0009, grad_fn=<AddBackward0>)\n",
      "0.018582806 0.021897767 0.104498476\n",
      "tensor(0.0009, grad_fn=<AddBackward0>)\n",
      "0.01835207 0.0216475 0.10313503\n",
      "tensor(0.0009, grad_fn=<AddBackward0>)\n",
      "0.018156886 0.021401387 0.10206782\n",
      "tensor(0.0009, grad_fn=<AddBackward0>)\n",
      "0.017963802 0.021158598 0.10101174\n",
      "tensor(0.0009, grad_fn=<AddBackward0>)\n",
      "0.017746923 0.020915251 0.099743694\n",
      "tensor(0.0009, grad_fn=<AddBackward0>)\n",
      "0.017566755 0.020668527 0.09880655\n",
      "tensor(0.0009, grad_fn=<AddBackward0>)\n",
      "0.017342843 0.020423796 0.0974855\n",
      "tensor(0.0009, grad_fn=<AddBackward0>)\n",
      "0.01714324 0.020182 0.09636188\n",
      "tensor(0.0009, grad_fn=<AddBackward0>)\n",
      "0.016959118 0.01994078 0.09538582\n",
      "tensor(0.0009, grad_fn=<AddBackward0>)\n",
      "0.016737552 0.019700743 0.094065204\n",
      "tensor(0.0009, grad_fn=<AddBackward0>)\n",
      "0.016551116 0.01946253 0.0930455\n",
      "tensor(0.0008, grad_fn=<AddBackward0>)\n",
      "0.016374484 0.019226665 0.09210923\n",
      "tensor(0.0008, grad_fn=<AddBackward0>)\n",
      "0.016160537 0.01898742 0.0908634\n",
      "tensor(0.0008, grad_fn=<AddBackward0>)\n",
      "0.015957877 0.01874955 0.08971036\n",
      "tensor(0.0008, grad_fn=<AddBackward0>)\n",
      "0.015759483 0.018517923 0.08856681\n",
      "tensor(0.0008, grad_fn=<AddBackward0>)\n",
      "0.015571302 0.018286731 0.0875232\n",
      "tensor(0.0008, grad_fn=<AddBackward0>)\n",
      "0.015374439 0.018054869 0.08640383\n",
      "tensor(0.0008, grad_fn=<AddBackward0>)\n",
      "0.015202437 0.017829148 0.085477084\n",
      "tensor(0.0008, grad_fn=<AddBackward0>)\n",
      "0.015031305 0.01760581 0.08455459\n",
      "tensor(0.0008, grad_fn=<AddBackward0>)\n",
      "0.014813928 0.017380545 0.083242126\n",
      "tensor(0.0008, grad_fn=<AddBackward0>)\n",
      "0.014657506 0.017163217 0.082440555\n",
      "tensor(0.0008, grad_fn=<AddBackward0>)\n",
      "0.014484612 0.016946925 0.081481226\n",
      "tensor(0.0008, grad_fn=<AddBackward0>)\n",
      "0.014295225 0.016728656 0.080405146\n",
      "tensor(0.0007, grad_fn=<AddBackward0>)\n",
      "0.014106493 0.016515648 0.0792945\n",
      "tensor(0.0007, grad_fn=<AddBackward0>)\n",
      "0.013938081 0.016302407 0.078373335\n",
      "tensor(0.0007, grad_fn=<AddBackward0>)\n",
      "0.013780448 0.016099295 0.07752399\n",
      "tensor(0.0007, grad_fn=<AddBackward0>)\n",
      "0.013600625 0.015892344 0.07647749\n",
      "tensor(0.0007, grad_fn=<AddBackward0>)\n",
      "0.013432088 0.015691679 0.075531214\n",
      "tensor(0.0007, grad_fn=<AddBackward0>)\n",
      "0.013265093 0.01549065 0.074581444\n",
      "tensor(0.0007, grad_fn=<AddBackward0>)\n",
      "0.013112954 0.0152984215 0.07376201\n",
      "tensor(0.0007, grad_fn=<AddBackward0>)\n",
      "0.012953315 0.015106144 0.07286508\n",
      "tensor(0.0007, grad_fn=<AddBackward0>)\n",
      "0.012779826 0.014911886 0.071845755\n",
      "tensor(0.0007, grad_fn=<AddBackward0>)\n",
      "0.012623867 0.014726798 0.07095902\n",
      "tensor(0.0007, grad_fn=<AddBackward0>)\n",
      "0.012479823 0.014547208 0.07016089\n",
      "tensor(0.0007, grad_fn=<AddBackward0>)\n",
      "0.012331319 0.014365817 0.069338426\n",
      "tensor(0.0006, grad_fn=<AddBackward0>)\n",
      "0.012194373 0.014191344 0.0685909\n",
      "tensor(0.0006, grad_fn=<AddBackward0>)\n",
      "0.0120447595 0.014018647 0.06772921\n",
      "tensor(0.0006, grad_fn=<AddBackward0>)\n",
      "0.011913044 0.013848668 0.06702106\n",
      "tensor(0.0006, grad_fn=<AddBackward0>)\n",
      "0.011775479 0.013679711 0.06625877\n",
      "tensor(0.0006, grad_fn=<AddBackward0>)\n",
      "0.011635919 0.013515654 0.06546447\n",
      "tensor(0.0006, grad_fn=<AddBackward0>)\n",
      "0.011490729 0.013353893 0.06461912\n",
      "tensor(0.0006, grad_fn=<AddBackward0>)\n",
      "0.011366991 0.013197001 0.063933425\n",
      "tensor(0.0006, grad_fn=<AddBackward0>)\n",
      "0.011235273 0.013043189 0.06317363\n",
      "tensor(0.0006, grad_fn=<AddBackward0>)\n",
      "0.011115627 0.012892036 0.06252139\n",
      "tensor(0.0006, grad_fn=<AddBackward0>)\n",
      "0.010991734 0.01274062 0.061835825\n",
      "tensor(0.0006, grad_fn=<AddBackward0>)\n",
      "0.01086198 0.012594713 0.061088204\n",
      "tensor(0.0006, grad_fn=<AddBackward0>)\n",
      "0.010737768 0.012452075 0.060361616\n",
      "tensor(0.0006, grad_fn=<AddBackward0>)\n",
      "0.010641661 0.0123124365 0.059897434\n",
      "tensor(0.0006, grad_fn=<AddBackward0>)\n",
      "0.010506673 0.012174209 0.059064582\n",
      "tensor(0.0006, grad_fn=<AddBackward0>)\n",
      "0.01042154 0.012044327 0.058659557\n",
      "tensor(0.0006, grad_fn=<AddBackward0>)\n",
      "0.01029602 0.011908617 0.057918448\n",
      "tensor(0.0005, grad_fn=<AddBackward0>)\n",
      "0.010184552 0.0117783705 0.057283297\n",
      "tensor(0.0005, grad_fn=<AddBackward0>)\n",
      "0.010078595 0.011651956 0.056669455\n",
      "tensor(0.0005, grad_fn=<AddBackward0>)\n",
      "0.0099765295 0.011525253 0.056114253\n",
      "tensor(0.0005, grad_fn=<AddBackward0>)\n",
      "0.009885447 0.011408457 0.055637535\n",
      "tensor(0.0005, grad_fn=<AddBackward0>)\n",
      "0.00978285 0.011286363 0.05505202\n",
      "tensor(0.0005, grad_fn=<AddBackward0>)\n",
      "0.009677288 0.011169573 0.054433372\n",
      "tensor(0.0005, grad_fn=<AddBackward0>)\n",
      "0.009593639 0.011055733 0.054005332\n",
      "tensor(0.0005, grad_fn=<AddBackward0>)\n",
      "0.009501024 0.010943171 0.053475436\n",
      "tensor(0.0005, grad_fn=<AddBackward0>)\n",
      "0.009408774 0.010830233 0.052973777\n",
      "tensor(0.0005, grad_fn=<AddBackward0>)\n",
      "0.009317194 0.010726373 0.052432932\n",
      "tensor(0.0005, grad_fn=<AddBackward0>)\n",
      "0.009223821 0.010614964 0.05191707\n",
      "tensor(0.0005, grad_fn=<AddBackward0>)\n",
      "0.009134114 0.010511146 0.05140471\n",
      "tensor(0.0005, grad_fn=<AddBackward0>)\n",
      "0.0090491 0.010406311 0.050934356\n",
      "tensor(0.0005, grad_fn=<AddBackward0>)\n",
      "0.008959718 0.01030857 0.050399676\n",
      "tensor(0.0005, grad_fn=<AddBackward0>)\n",
      "0.008890971 0.010210946 0.050051857\n",
      "tensor(0.0005, grad_fn=<AddBackward0>)\n",
      "0.008800865 0.010112854 0.04952989\n",
      "tensor(0.0005, grad_fn=<AddBackward0>)\n",
      "0.00871582 0.010012417 0.04905979\n",
      "tensor(0.0005, grad_fn=<AddBackward0>)\n",
      "0.008640734 0.00992318 0.0486213\n",
      "tensor(0.0005, grad_fn=<AddBackward0>)\n",
      "0.00855196 0.009828075 0.048083995\n",
      "tensor(0.0005, grad_fn=<AddBackward0>)\n",
      "0.008481421 0.009733315 0.04774122\n",
      "tensor(0.0005, grad_fn=<AddBackward0>)\n",
      "0.008415413 0.009651637 0.04737665\n",
      "tensor(0.0005, grad_fn=<AddBackward0>)\n",
      "0.008340785 0.00956004 0.046956405\n",
      "tensor(0.0005, grad_fn=<AddBackward0>)\n",
      "0.008263178 0.009471605 0.046512455\n",
      "tensor(0.0004, grad_fn=<AddBackward0>)\n",
      "0.008183138 0.009392709 0.04601848\n",
      "tensor(0.0004, grad_fn=<AddBackward0>)\n",
      "0.008120258 0.009306494 0.045678657\n",
      "tensor(0.0004, grad_fn=<AddBackward0>)\n",
      "0.008044648 0.009225365 0.045239475\n",
      "tensor(0.0004, grad_fn=<AddBackward0>)\n",
      "0.007994027 0.0091464305 0.045010965\n",
      "tensor(0.0004, grad_fn=<AddBackward0>)\n",
      "0.007935753 0.009069019 0.044703707\n",
      "tensor(0.0004, grad_fn=<AddBackward0>)\n",
      "0.007828471 0.00897824 0.04401871\n",
      "tensor(0.0004, grad_fn=<AddBackward0>)\n",
      "0.0077784946 0.008910701 0.043742687\n",
      "tensor(0.0004, grad_fn=<AddBackward0>)\n",
      "0.0077254395 0.008832643 0.04349232\n",
      "tensor(0.0004, grad_fn=<AddBackward0>)\n",
      "0.0076546604 0.008752031 0.04309478\n",
      "tensor(0.0004, grad_fn=<AddBackward0>)\n",
      "0.0075867865 0.008681227 0.04269241\n",
      "tensor(0.0004, grad_fn=<AddBackward0>)\n",
      "0.0075258845 0.008611012 0.04232185\n",
      "tensor(0.0004, grad_fn=<AddBackward0>)\n",
      "0.007481375 0.008540825 0.042131223\n",
      "tensor(0.0004, grad_fn=<AddBackward0>)\n",
      "0.00740313 0.0084638605 0.04164559\n",
      "tensor(0.0004, grad_fn=<AddBackward0>)\n",
      "0.007355168 0.00839661 0.041414645\n",
      "tensor(0.0004, grad_fn=<AddBackward0>)\n",
      "0.0073004905 0.0083250515 0.041132916\n",
      "tensor(0.0004, grad_fn=<AddBackward0>)\n",
      "0.007231417 0.008259623 0.040685475\n",
      "tensor(0.0004, grad_fn=<AddBackward0>)\n",
      "0.0071879863 0.008195613 0.04049192\n",
      "tensor(0.0004, grad_fn=<AddBackward0>)\n",
      "0.007125727 0.0081329895 0.04010268\n",
      "tensor(0.0004, grad_fn=<AddBackward0>)\n",
      "0.0070700725 0.0080650775 0.03979588\n",
      "tensor(0.0004, grad_fn=<AddBackward0>)\n",
      "0.007027073 0.00800602 0.039578333\n",
      "tensor(0.0004, grad_fn=<AddBackward0>)\n",
      "0.00696083 0.007931059 0.039206404\n",
      "tensor(0.0004, grad_fn=<AddBackward0>)\n",
      "0.006908272 0.007877245 0.03887185\n",
      "tensor(0.0004, grad_fn=<AddBackward0>)\n",
      "0.006852631 0.0078055304 0.03858413\n",
      "tensor(0.0004, grad_fn=<AddBackward0>)\n",
      "0.006802336 0.007749315 0.038288828\n",
      "tensor(0.0004, grad_fn=<AddBackward0>)\n",
      "0.006749357 0.007690703 0.037996676\n",
      "tensor(0.0004, grad_fn=<AddBackward0>)\n",
      "0.006711767 0.0076363464 0.03780779\n",
      "tensor(0.0004, grad_fn=<AddBackward0>)\n",
      "0.0066527463 0.007570259 0.037470065\n",
      "tensor(0.0004, grad_fn=<AddBackward0>)\n",
      "0.0065995613 0.0075117727 0.037171178\n",
      "tensor(0.0004, grad_fn=<AddBackward0>)\n",
      "0.0065509863 0.007449308 0.03690294\n",
      "tensor(0.0004, grad_fn=<AddBackward0>)\n",
      "0.0065087005 0.00740676 0.036633797\n",
      "tensor(0.0004, grad_fn=<AddBackward0>)\n",
      "0.006476274 0.007354594 0.036478978\n",
      "tensor(0.0004, grad_fn=<AddBackward0>)\n",
      "0.006404619 0.00728772 0.03605462\n",
      "tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "0.0063715787 0.0072288234 0.035931524\n",
      "tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "0.0063231043 0.007184903 0.035588272\n",
      "tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "0.0062814686 0.0071234205 0.03543486\n",
      "tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "0.006218651 0.0070739565 0.035002433\n",
      "tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "0.00618448 0.0070181214 0.034848\n",
      "tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "0.006151324 0.006974993 0.03465401\n",
      "tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "0.006089767 0.006915735 0.034292817\n",
      "tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "0.0060550733 0.0068674833 0.034135304\n",
      "tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "0.006009092 0.00681887 0.03385903\n",
      "tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "0.0059797713 0.006781049 0.033664864\n",
      "tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "0.005926555 0.0067187455 0.03340483\n",
      "tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "0.0058836252 0.006671203 0.033168674\n",
      "tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "0.0058457255 0.0066271485 0.03293844\n",
      "tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "0.0058032414 0.0065721045 0.03272505\n",
      "tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "0.005760921 0.006522608 0.03246543\n",
      "tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "0.0057194666 0.00647231 0.03225803\n",
      "tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "0.0056968834 0.0064361496 0.032170568\n",
      "tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "0.005654006 0.006393642 0.03188671\n",
      "tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "0.0056111757 0.0063398173 0.03166143\n",
      "tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "0.0055697947 0.006304054 0.03140283\n",
      "tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "0.005531268 0.006260164 0.031216187\n",
      "tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "0.0054890043 0.0062157037 0.030917136\n",
      "tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "0.0054555717 0.0061700856 0.030768586\n",
      "tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "0.0054286467 0.006128658 0.030635474\n",
      "tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "0.005397368 0.0060850703 0.030482506\n",
      "tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "0.005330225 0.0060342997 0.03003915\n",
      "tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "0.005308283 0.0059904726 0.029977221\n",
      "tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "0.005277887 0.005956655 0.029799879\n",
      "tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "0.005230899 0.0059082615 0.029535327\n",
      "tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "0.005188543 0.0058691823 0.029253539\n",
      "tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "0.005176197 0.0058266525 0.029262701\n",
      "tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "0.0051326123 0.005785566 0.028993633\n",
      "tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "0.0050927056 0.005741421 0.028780866\n",
      "tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "0.0050663757 0.0057176896 0.028590763\n",
      "tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "0.0050393934 0.0056770314 0.028480006\n",
      "tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "0.0050143823 0.005639528 0.028347058\n",
      "tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "0.0049758735 0.0055954405 0.028130373\n",
      "tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "0.0049342504 0.0055516185 0.027885938\n",
      "tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "0.004896427 0.0055217003 0.027645176\n",
      "tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "0.0048559825 0.005461684 0.027448837\n",
      "tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "0.0048313234 0.0054354537 0.027309118\n",
      "tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "0.004807032 0.0054011596 0.027206816\n",
      "tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "0.0047699385 0.0053706015 0.02693916\n",
      "tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "0.0047263564 0.005315784 0.026747845\n",
      "tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "0.0046945694 0.005280852 0.026556041\n",
      "tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "0.004670046 0.00525 0.026388569\n",
      "tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "0.004636969 0.00521222 0.026224224\n",
      "tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "0.004613724 0.005178398 0.026164567\n",
      "tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "0.004573928 0.005132933 0.02591412\n",
      "tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "0.004548667 0.005108916 0.025714846\n",
      "tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "0.004520139 0.005068063 0.025574291\n",
      "tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "0.0044945045 0.0050318455 0.025470752\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "0.004463303 0.0049986923 0.025294092\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "0.004429712 0.0049663265 0.025091631\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "0.0043989434 0.0049296236 0.024934638\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "0.0043692193 0.0048945523 0.024778683\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "0.004346454 0.0048675914 0.024631562\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "0.0043133693 0.0048263054 0.024448168\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "0.0042838077 0.004801242 0.024232766\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "0.0042488473 0.0047588465 0.02405949\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "0.0042287735 0.00472638 0.02397693\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "0.0041800477 0.0046784948 0.023735054\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "0.0041781846 0.00465743 0.023756312\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "0.0041255937 0.0046140067 0.023421707\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "0.0041144537 0.00459758 0.023379698\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "0.004063033 0.0045491457 0.023047732\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "0.0040693 0.00453903 0.023104195\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "0.0040102242 0.0044883867 0.02275365\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "0.0039911596 0.0044524786 0.022732364\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "0.003974252 0.004441291 0.02256843\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "0.0039357455 0.004396705 0.022369523\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "0.0039016271 0.004359583 0.02214617\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "0.0038831737 0.004324406 0.022151778\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "0.003855871 0.00429792 0.021955527\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "0.003845513 0.004263879 0.021964647\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "0.0038120723 0.0042393613 0.021737488\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "0.003778144 0.0042128796 0.02149124\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "0.0037385367 0.0041687717 0.021276368\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "0.0037349395 0.0041543073 0.021306537\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "0.0036934467 0.0041085267 0.021070316\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "0.0036565657 0.004076256 0.02085453\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "0.0036441241 0.004059673 0.020757899\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "0.0036263173 0.004029333 0.020712707\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "0.0036013632 0.003986867 0.020631595\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "0.0035982386 0.003976504 0.0205686\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "0.0035535356 0.0039335308 0.020332688\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "0.0035126093 0.0039032674 0.020057729\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "0.003504416 0.0038832093 0.02002796\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "0.0034704485 0.0038455373 0.019922115\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "0.0034517103 0.0038192032 0.019775303\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "0.0034253297 0.0037876589 0.019642517\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "0.0033872705 0.0037608559 0.01939396\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "0.0033779603 0.0037318955 0.01936587\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "0.0033387004 0.003705658 0.019120889\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "0.0033133102 0.003667708 0.019044686\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "0.0033153878 0.003652353 0.019048447\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "0.0032839803 0.003611355 0.018947981\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "0.003271436 0.0035933852 0.018893154\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "0.003233834 0.0035662549 0.018588135\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "0.003216325 0.0035377934 0.018570771\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "0.0031950404 0.0035142638 0.018439222\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "0.0031621146 0.0034913607 0.018191962\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "0.0031300532 0.003460687 0.017981885\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "0.0031194629 0.0034307232 0.018000325\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "0.0030984671 0.003406852 0.017903624\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "0.0030772784 0.003379542 0.017845605\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "0.003062805 0.0033609013 0.017688967\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "0.0030339214 0.0033302614 0.017560657\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "0.003021873 0.0033140543 0.017508194\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "0.0029788448 0.0032729185 0.017277682\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "0.002952555 0.0032513204 0.017154481\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "0.0029512073 0.0032283908 0.01718404\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "0.0029429847 0.0032196334 0.017100513\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "0.0029028119 0.0031808582 0.016922833\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "0.0028804762 0.003158951 0.016766861\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "0.0028679501 0.0031399145 0.016721783\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "0.0028370798 0.0031089594 0.016614025\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "0.0028163441 0.0030824295 0.016407128\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "0.0028186208 0.0030596012 0.01656691\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "0.0027897414 0.003047766 0.016316505\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "0.0027793078 0.0030231408 0.016368063\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "0.002752563 0.0029980086 0.016124027\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "0.002738973 0.0029742976 0.016100118\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "0.0027222235 0.0029529838 0.016113399\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "0.002694285 0.0029452066 0.015822247\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "0.0026777764 0.002907664 0.015744308\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "0.0026606296 0.0028867247 0.015681978\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "0.0026402723 0.0028661988 0.015611852\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "0.0026171652 0.0028413176 0.015425311\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "0.0026221268 0.0028307019 0.015513668\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "0.002600028 0.002818985 0.015358463\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "0.0025685448 0.0027880978 0.015162481\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "0.0025476958 0.0027721648 0.015023019\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.002539157 0.0027415755 0.01511539\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "0.0024898006 0.0026993537 0.014877742\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0024962535 0.0027033566 0.014819111\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0024686852 0.0026864612 0.014619662\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.002465184 0.0026694848 0.014703941\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0024655887 0.0026526793 0.014735855\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0024445036 0.0026366832 0.01460538\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0024201174 0.0026153994 0.01446567\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0023954748 0.0025939445 0.014340941\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0023986516 0.0025809149 0.014413929\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0023933325 0.0025706217 0.014335609\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.002371122 0.0025527657 0.014221163\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0023462474 0.002534372 0.014057762\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0023488593 0.0025128322 0.014132977\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0023339302 0.002495634 0.014163982\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0023280657 0.0024858552 0.014112117\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0022701917 0.002457885 0.013758768\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0022924044 0.0024557346 0.013863327\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0022585175 0.0024131786 0.013794272\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0022624335 0.0024144684 0.013762032\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0022359942 0.0024082405 0.0135105075\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0022301795 0.00238183 0.013574502\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.002227099 0.002373073 0.013693185\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0022181498 0.002356582 0.013533622\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0022014636 0.0023424074 0.013536545\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.002179491 0.0023370902 0.01336189\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0021931864 0.0023395866 0.013428554\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.002171812 0.0023144335 0.013340006\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.00215875 0.002293752 0.013271738\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0021526637 0.0022722913 0.013471085\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0021438594 0.002283108 0.013073811\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0021168962 0.0022453647 0.013206092\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0021213277 0.0022603108 0.013022249\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0020903186 0.0022228654 0.013015906\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.00208442 0.0022230032 0.012863484\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0020783092 0.002197033 0.0130853215\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.002088307 0.0021987972 0.012998281\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0020644509 0.002180131 0.012958056\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0020431443 0.0021626763 0.012800713\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.00201318 0.0021531698 0.012456228\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0020314986 0.0021438552 0.012722456\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0020456326 0.0021473106 0.012819795\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.002002846 0.0021019985 0.012748021\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.002005639 0.0021163747 0.012644158\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0020055773 0.0021036065 0.012700792\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0020043624 0.002110003 0.012639781\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0019701656 0.0020815402 0.012395448\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0019686546 0.002078025 0.012392917\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0019610159 0.002056729 0.012459417\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0019472586 0.0020482643 0.012389369\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0019390669 0.00203342 0.012437378\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0019291976 0.002029508 0.0123802945\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0019256881 0.0020205642 0.012372233\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0019110315 0.002014872 0.01214016\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0019063093 0.0020092193 0.012130048\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0018923816 0.0019932112 0.012158106\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0018863999 0.0019916834 0.012254684\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0018924976 0.001983238 0.012049865\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0018813419 0.0019680988 0.011907702\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0018863878 0.0019663908 0.012051544\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0018620602 0.0019495124 0.012043024\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0018702756 0.0019247693 0.012384133\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0018455301 0.0019377479 0.011949958\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0018302542 0.0019303195 0.011746673\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0018373996 0.0019109817 0.012045948\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0018471625 0.0019147386 0.011998227\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0018061363 0.00188217 0.011804864\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0018034367 0.0018849856 0.0118019385\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0018160885 0.001886902 0.011952476\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0018036444 0.0018742689 0.011852757\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0017934879 0.001869029 0.011904633\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0017797601 0.0018548336 0.011776731\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0017769582 0.0018532164 0.0117411\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0017702337 0.0018335147 0.011692148\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0017749828 0.0018419352 0.0116618825\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0017832245 0.0018428932 0.011827583\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.001753561 0.0018180752 0.0116733685\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0017517689 0.0018129126 0.011748387\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0017537378 0.0018109838 0.011740876\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.001730077 0.0017956338 0.011662314\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0017157733 0.0017839267 0.011374487\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.001707669 0.0017843161 0.011365683\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0017326451 0.0017854561 0.011570169\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0017161006 0.0017759841 0.011538516\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0017078931 0.0017619425 0.011411037\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0016927487 0.0017535967 0.0114666745\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0016940235 0.0017605548 0.011339223\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0017005752 0.0017461036 0.011673372\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0016827268 0.0017324006 0.011403881\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0016906158 0.0017376784 0.011439245\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0016959455 0.0017407724 0.011520981\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0016924475 0.0017377048 0.011548052\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0016692965 0.0017219327 0.011370009\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.001669689 0.0017140371 0.011408118\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.001639071 0.0016932011 0.011203684\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0016484152 0.0016845233 0.011265309\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0016382055 0.0016834912 0.011093775\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.001630862 0.0016934355 0.011305968\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0016396818 0.0016881987 0.011196243\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0016502553 0.0016847769 0.01155074\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0016563948 0.0016861013 0.011339193\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0016255042 0.0016692496 0.011156365\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0016446769 0.0016800866 0.011500406\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0016321818 0.0016617277 0.011326916\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.001604526 0.0016553737 0.011029306\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0016136552 0.0016457269 0.011404102\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0016106161 0.0016598812 0.010983404\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0016148221 0.0016415064 0.011336868\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0015725233 0.0016304379 0.010918416\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.001605247 0.0016391808 0.011200955\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0015805083 0.0016262849 0.011001944\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0015786302 0.0016110562 0.011158349\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0015709683 0.0016131322 0.010990368\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0015860074 0.0016142735 0.011494675\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0015619484 0.0016012939 0.011338597\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0015766949 0.0016146622 0.010957424\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0015549215 0.001604529 0.0110005075\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0015636026 0.0015907378 0.011154169\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0015389917 0.0015810482 0.0108630145\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.00154864 0.0015867514 0.01082776\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0015325723 0.0015766342 0.010796792\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0015269782 0.001571591 0.011041145\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0015561003 0.0015885405 0.011077618\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0015454135 0.0015673344 0.011110251\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0015157152 0.0015509841 0.010978489\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0015220359 0.0015605437 0.010868485\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0015500602 0.0015671746 0.011127813\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.001525779 0.0015537457 0.011289338\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0015235355 0.0015410538 0.011138599\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0015208377 0.0015473298 0.011283281\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0015151503 0.0015506959 0.010667158\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0015172163 0.0015379392 0.010923753\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0014872792 0.0015242923 0.010597382\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0015038998 0.0015359846 0.010927909\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0015129247 0.0015417777 0.010930758\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0014873813 0.0015199968 0.0108423\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0015085826 0.0015315728 0.010859919\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0015041078 0.0015306766 0.010869234\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0014843438 0.001511399 0.010965602\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0015095524 0.0015203218 0.011023738\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0014853618 0.0015201031 0.010832775\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0014875706 0.0015070271 0.01074714\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0014777918 0.0015008707 0.0109985275\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.001484062 0.001503764 0.010955051\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0014864067 0.0015001314 0.01099906\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0014932676 0.0015043328 0.011107275\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0014895251 0.0015049231 0.011089967\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0014856884 0.0015139999 0.010894688\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0014993185 0.0015090612 0.011067156\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0014752136 0.0015039163 0.010889118\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0014706287 0.0015000668 0.011019523\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0014860327 0.0015037915 0.011120352\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0014775031 0.0014950425 0.010931028\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0014691139 0.0014885082 0.011072815\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0014879713 0.0014967207 0.010904486\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0014634024 0.001477249 0.011111468\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0014601566 0.0014885635 0.010839529\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0014680803 0.0015006742 0.01083965\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0014588366 0.0014775431 0.0109770605\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0014808255 0.0014935101 0.010842191\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0014605067 0.0014650428 0.011126554\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0014528766 0.0014783678 0.01105255\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0014590056 0.0014825076 0.011058751\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0014324002 0.0014636583 0.010880438\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0014562748 0.001470186 0.010994727\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0014452459 0.0014585356 0.011040488\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0014715008 0.0014722531 0.01113921\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.00142748 0.00144893 0.010831006\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.001451496 0.0014684995 0.01084798\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0014371031 0.0014570968 0.010961031\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0014367722 0.0014480981 0.011200466\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0014259936 0.0014530491 0.0105792815\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0014608194 0.0014554597 0.011168476\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0014261188 0.0014474951 0.010947861\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0014207176 0.0014381357 0.011167053\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0014377362 0.0014590919 0.010962851\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0014256553 0.0014418133 0.010881609\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.001437934 0.0014450714 0.01080869\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0014298257 0.0014497597 0.010921522\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0014237782 0.0014437691 0.010837664\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.001426566 0.0014302628 0.010810947\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0014237557 0.0014307342 0.010995132\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0014086324 0.0014281912 0.010930476\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0014343843 0.0014374644 0.010916297\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0014080532 0.0014130172 0.011264098\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0014162516 0.0014227454 0.011097833\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0014350609 0.0014332179 0.01103315\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0014310919 0.0014368505 0.010950227\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0014192406 0.0014352046 0.010929223\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013983267 0.0014151436 0.010872509\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0014183292 0.001437897 0.010968307\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0014167808 0.0014248135 0.011071265\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0014273968 0.0014284701 0.011325377\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0014061247 0.001417331 0.010996343\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013852883 0.0014166791 0.010964472\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013935904 0.0014084332 0.01082964\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.001392874 0.001421222 0.010776624\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013877678 0.0014180114 0.010603096\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0014063446 0.0014131415 0.011017563\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0014035979 0.0013996372 0.011223545\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013994967 0.0014135084 0.010759252\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013936064 0.0014117296 0.010831025\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0014037935 0.0014066647 0.011199383\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013850351 0.0014020198 0.010640499\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013856143 0.0013977129 0.010978507\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013783852 0.0014049044 0.010759049\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013936106 0.0014061957 0.0108674085\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013947155 0.0014017756 0.01071973\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013790218 0.0013908072 0.010923776\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013922808 0.0014024547 0.010990297\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013866419 0.0014013338 0.010944643\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013902414 0.0014001484 0.0110867005\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013732458 0.0013930405 0.011058695\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013764191 0.0013954438 0.010648837\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013513833 0.0013799886 0.010781632\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013912304 0.0013998569 0.010784819\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013980555 0.0013935002 0.010977613\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013723434 0.0013882276 0.010702181\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013721222 0.0013842415 0.01100527\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013772901 0.0013815468 0.010973347\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013712833 0.0013831515 0.010987638\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013729725 0.001380016 0.01112293\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013751779 0.0013725378 0.011228826\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013701697 0.0013664794 0.011336191\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013794691 0.0013800517 0.011395659\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013632746 0.0013732272 0.011001783\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013694805 0.0013754918 0.011018731\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013684833 0.0013802326 0.011096908\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013478072 0.0013731017 0.011017992\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013745261 0.0013697218 0.011121838\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.001375986 0.00137804 0.011102267\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013607446 0.0013587935 0.011259565\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013730152 0.0013709015 0.011155386\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013805954 0.001374539 0.010929484\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013632587 0.0013658227 0.011165838\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013619809 0.0013627653 0.011369853\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013334084 0.0013586532 0.011006326\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013764442 0.0013793369 0.010985915\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013594636 0.0013620369 0.011117846\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013568951 0.0013567329 0.010888001\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013644451 0.0013720997 0.01088987\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.001361748 0.0013819711 0.010868314\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013811336 0.0013952029 0.010759987\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013712414 0.0013595342 0.011240339\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013515988 0.0013616547 0.0109334495\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013409472 0.0013532677 0.010910108\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013598326 0.0013529164 0.011244336\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013400218 0.0013633237 0.010886399\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013604442 0.0013683361 0.010917393\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013638479 0.0013690795 0.010973018\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013517996 0.001358824 0.010970054\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013578369 0.001376551 0.010990259\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013563279 0.0013658025 0.010907664\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013438305 0.0013411199 0.011422612\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013626716 0.0013598205 0.0109189\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013742938 0.0013581839 0.011279274\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013601471 0.0013619364 0.010928949\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013438693 0.0013343991 0.01118717\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013447551 0.0013549834 0.011020084\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013400427 0.0013448293 0.011072132\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013513883 0.001355107 0.010919093\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013483632 0.001350183 0.011218548\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013470756 0.0013555833 0.010855174\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013464215 0.0013486515 0.010961285\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013620412 0.0013725929 0.010918061\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013372457 0.0013512226 0.010845475\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.001343813 0.0013379093 0.011283507\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013415947 0.0013482678 0.011116597\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.001333355 0.0013437386 0.011136171\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013312838 0.0013360811 0.011148412\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013683229 0.0013501184 0.011503465\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013337729 0.0013519928 0.010737297\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013352459 0.0013402423 0.010740179\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013377258 0.001334568 0.011036744\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013302206 0.0013390937 0.010856859\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013531325 0.0013489099 0.011406151\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013332368 0.0013398264 0.011183863\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013340766 0.0013493978 0.010655244\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013161167 0.0013297253 0.011164572\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013141681 0.0013261043 0.010756588\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.001332664 0.0013317269 0.011300933\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013198784 0.001326786 0.011373471\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013331756 0.0013445669 0.010828155\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013277347 0.0013283914 0.011086607\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013434318 0.0013505891 0.011025872\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013284198 0.0013403678 0.010999782\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013410259 0.0013469718 0.011044141\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013342828 0.001339528 0.011000197\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013456522 0.0013416536 0.011053975\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013358272 0.0013441169 0.010942463\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013274534 0.0013314344 0.010966021\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013547307 0.0013518729 0.010734477\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013268411 0.001340156 0.011068863\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013462289 0.0013562875 0.010997962\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013275709 0.0013454654 0.01075176\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013117517 0.0013226079 0.011120645\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013154286 0.001321139 0.010818169\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013518676 0.0013490706 0.011085807\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013379852 0.0013283549 0.0110333925\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013213168 0.0013330288 0.011009245\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013262972 0.0013318788 0.011058012\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013376032 0.0013473054 0.011002468\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013224946 0.0013273509 0.01116502\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013490536 0.001331444 0.011584945\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013279207 0.0013316604 0.011083517\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013500378 0.0013391979 0.011071606\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013068536 0.0013239458 0.011073985\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013174445 0.0013227483 0.011192928\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013295264 0.0013243569 0.011076527\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013283725 0.0013182719 0.011135512\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013255297 0.0013192866 0.011406112\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013215939 0.0013264864 0.011135178\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013167339 0.0013253251 0.010925916\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013173921 0.0013171291 0.0111899385\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013114752 0.0013154432 0.011017595\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013294409 0.0013417883 0.0108455755\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013272916 0.0013321944 0.0110484855\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.001313497 0.0013268408 0.011235056\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013270706 0.0013230061 0.010899765\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013203254 0.001327666 0.011198848\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.001329495 0.0013226994 0.011134567\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013008364 0.0013145903 0.011178044\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013235799 0.0013246515 0.01084691\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013194132 0.0013215645 0.011089546\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013233968 0.0013225579 0.011095431\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013271129 0.0013376863 0.011233481\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013471552 0.0013409267 0.011106578\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013296716 0.0013337058 0.010930432\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013287163 0.00133608 0.010957899\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013053643 0.0013165058 0.011140337\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013241813 0.0013282715 0.011396184\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013335232 0.001331955 0.011273237\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013295071 0.001321676 0.011456796\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013376629 0.0013449225 0.010971372\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013501853 0.0013575626 0.010920271\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013059188 0.0013145382 0.01133028\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013269365 0.0013296492 0.011087653\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013368798 0.0013403674 0.010841327\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013386786 0.0013365389 0.011298213\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013231377 0.0013224742 0.011258754\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013218035 0.0013283746 0.011042487\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013411044 0.0013375977 0.011102398\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013260554 0.0013240102 0.0113269985\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013266017 0.0013307886 0.011397327\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0012962834 0.001318514 0.011036109\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013303821 0.0013296608 0.011074347\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013168426 0.0013250926 0.011233948\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.00133675 0.0013189155 0.011409833\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013206112 0.0013241335 0.011103254\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013083539 0.0013176135 0.011200518\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013218474 0.0013200389 0.011538839\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.001305604 0.0013200808 0.011029163\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013120607 0.0013230324 0.010840793\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013222491 0.0013262598 0.011120966\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013050182 0.001312139 0.01133755\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013233239 0.0013172944 0.011554116\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013366692 0.001327028 0.011325868\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013307988 0.0013176716 0.011700456\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013472781 0.0013332037 0.011457485\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013358259 0.0013352396 0.011102338\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013220292 0.0013226287 0.011296617\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013301497 0.0013318312 0.011087903\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013206715 0.0013257972 0.011206436\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013402406 0.0013336113 0.011190588\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.001306485 0.0013160415 0.011181966\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.001291054 0.0013160299 0.011058672\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013205031 0.0013190785 0.011412933\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013048586 0.0013224668 0.011131702\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013296029 0.0013251273 0.011182878\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013367418 0.0013220662 0.011371759\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013100535 0.001319791 0.010994458\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013429833 0.0013353588 0.0112672495\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013041733 0.0013173119 0.011204047\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013060902 0.0013272822 0.011187388\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013323752 0.0013138431 0.011371966\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013197041 0.0013193445 0.01120825\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013160758 0.0013206698 0.011056771\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013314931 0.0013229 0.011154497\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013234155 0.0013113549 0.011082736\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013156335 0.0013243665 0.010913177\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.001309414 0.0013205791 0.011068534\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013062845 0.0013159717 0.011063747\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013192558 0.0013156818 0.011397331\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013094061 0.0013022402 0.011331401\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013173189 0.0013103834 0.011295346\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013254368 0.0013292121 0.011155453\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0012907574 0.0013087863 0.011266625\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013257485 0.001309661 0.011369786\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.001309311 0.0013170319 0.01123735\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013140236 0.0013150125 0.011284311\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0012997581 0.0013076403 0.01130789\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013280454 0.0013143828 0.011374658\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013247874 0.0013266879 0.011066784\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013159189 0.0013212177 0.01110728\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013186937 0.0013157882 0.011197141\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013182019 0.0013324987 0.010980586\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.001306855 0.001302677 0.011391945\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013049616 0.00130899 0.011199924\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013118042 0.001319515 0.011032766\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0012921328 0.0013096618 0.011129265\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013409824 0.0013240277 0.011640269\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013079164 0.0013043566 0.011128043\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0012959301 0.0013021115 0.011329215\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0012857852 0.0013010084 0.011266311\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013236869 0.0013257066 0.010958958\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013286149 0.0013322748 0.010914533\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0012913249 0.0013073564 0.0113391755\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013068691 0.0013122426 0.011275404\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0012845005 0.001315068 0.011130718\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013148715 0.0013054545 0.01136991\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013192688 0.0013148439 0.011337586\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013082862 0.001312546 0.011116985\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.001301595 0.0013132585 0.011097026\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013123207 0.0013077222 0.011423611\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013102579 0.0013146035 0.011023377\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013147038 0.0013077541 0.01141198\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013197544 0.0013161667 0.011226665\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013300899 0.0013234136 0.011342137\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013159845 0.0013121908 0.011533801\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013313342 0.0013167514 0.011308837\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.001330717 0.001309071 0.011579791\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0012954329 0.0013134023 0.0111913355\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0012994901 0.0013086845 0.011251855\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.001298482 0.0012975946 0.011440348\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0012930335 0.0013053283 0.011419114\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0012940235 0.0012999426 0.011107862\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013421205 0.0013224867 0.011822687\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013344439 0.0013157288 0.011357667\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.00131555 0.0013079682 0.011162372\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013267607 0.0013189723 0.011423288\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013182943 0.0012965305 0.011484409\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013145899 0.0013108833 0.011223687\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0012910661 0.0013177543 0.011000746\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013238846 0.0013089951 0.011048962\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013028849 0.0013153596 0.011038649\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013225385 0.0013209849 0.011018492\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.001295854 0.0013070871 0.011180049\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013063425 0.0013038125 0.011300356\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0012882545 0.0012973496 0.011186307\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013261402 0.0013229998 0.0110602155\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013106291 0.0013259077 0.010869511\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0012994584 0.0013047819 0.011281578\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013147525 0.0013120763 0.011223031\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013135065 0.0013111924 0.011249804\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0012896669 0.0013079371 0.0109044565\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013009654 0.0013009036 0.011230587\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013215566 0.0013097915 0.011237773\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.001304995 0.0013109791 0.011347073\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013085862 0.0013106745 0.010905574\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013011886 0.0013054372 0.011283666\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.001302826 0.0013014927 0.011094642\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013078757 0.0013073987 0.011144207\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.001322761 0.0013159852 0.010998705\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0012976867 0.0012943941 0.011374738\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0012868135 0.0013039258 0.011163115\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0012924649 0.0013046657 0.011010357\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.001323583 0.0013190567 0.011189474\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013225586 0.001311962 0.010818315\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0012773746 0.0012937421 0.011072329\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013223777 0.001306531 0.011458383\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013034297 0.0013054842 0.011292171\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013094062 0.0013096735 0.011085903\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013123987 0.0013145836 0.011159651\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0012871125 0.0013006602 0.010956791\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013200429 0.0013195628 0.011109306\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0012789987 0.0012867517 0.011603193\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013041424 0.0013170202 0.011037398\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0012849463 0.0013000673 0.011376376\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013011534 0.0013064555 0.011135518\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013060472 0.0012980025 0.0113626085\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013112776 0.0013015654 0.011340668\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013102978 0.0013101428 0.0113151055\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013028187 0.0013109846 0.01097264\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013063557 0.0013120873 0.011437917\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0012907458 0.0012962501 0.011004062\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0012896855 0.0013055294 0.01102125\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013021466 0.0013098159 0.010872929\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013079928 0.0013027014 0.011175849\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013023267 0.0013078201 0.010921173\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0012894921 0.001303262 0.011213817\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.001307253 0.0013017068 0.011007446\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013116318 0.0013100713 0.011074522\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0012957932 0.0013010256 0.011191797\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013025375 0.001296858 0.011269272\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013007201 0.0012927646 0.011361726\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013110803 0.0013036405 0.011476929\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.001299499 0.0012996802 0.01102212\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013011908 0.0013002966 0.011552623\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013022097 0.0012981467 0.011232815\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.001306755 0.0013095398 0.01113213\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0012813325 0.0013054919 0.010976156\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0012889474 0.0013070488 0.0112589\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013129615 0.001301626 0.011050029\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013109259 0.0013032167 0.011391819\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013041857 0.0013057144 0.011469755\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0012990526 0.0012905453 0.01148764\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013236518 0.0013062179 0.010984776\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013064502 0.0013069777 0.011298916\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013089092 0.0012996667 0.011250064\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013109164 0.001307182 0.011265071\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013163132 0.0012968293 0.011565378\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0012863763 0.0012966233 0.0112405745\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013141143 0.0013034976 0.011320734\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0012998506 0.001303803 0.01118061\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013194872 0.0013073196 0.011311762\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0012944716 0.0012980188 0.011287596\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0012844445 0.0012863637 0.01142417\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0012929657 0.0013005151 0.011340232\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0012985651 0.0012999248 0.011095054\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013025467 0.0013090648 0.010976036\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0012926792 0.0012954104 0.011169376\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0012980204 0.0012963669 0.011406274\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0012769935 0.0012943557 0.010916551\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013006178 0.0013014498 0.010881355\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "0.0013031928 0.0013012447 0.011377034\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10000\u001b[39m):\n\u001b[1;32m      3\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m----> 4\u001b[0m     output \u001b[38;5;241m=\u001b[39m n\u001b[38;5;241m.\u001b[39mforward(\u001b[43mg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnormed_adjMats_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnode_sigs_train\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      5\u001b[0m     loss \u001b[38;5;241m=\u001b[39m lossF(output)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(loss)\n",
      "File \u001b[0;32m/var/folders/y9/sgsdqvs575j76jqnz728mwkh0000gn/T/ipykernel_52177/474890613.py:16\u001b[0m, in \u001b[0;36mGCN.forward\u001b[0;34m(self, adjM, node_sigM)\u001b[0m\n\u001b[1;32m     14\u001b[0m curr_output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtanh(torch\u001b[38;5;241m.\u001b[39mmatmul(torch\u001b[38;5;241m.\u001b[39mmatmul(adjM,node_sigM),\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights[\u001b[38;5;241m0\u001b[39m])) \u001b[38;5;66;03m#nxc\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidths)):\n\u001b[0;32m---> 16\u001b[0m     curr_output \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtanh\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43madjM\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcurr_output\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#nxc\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m curr_output\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(g.weights + n.weights,lr = 0.0001)\n",
    "for i in range(10000):\n",
    "    optimizer.zero_grad()\n",
    "    output = n.forward(g.forward(normed_adjMats_train,node_sigs_train))\n",
    "    loss = lossF(output)\n",
    "    print(loss)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y9/sgsdqvs575j76jqnz728mwkh0000gn/T/ipykernel_52177/4182074172.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  mask_same = torch.tensor(label_mat_train - torch.diag(torch.ones(450)),dtype=bool).flatten()\n",
      "/var/folders/y9/sgsdqvs575j76jqnz728mwkh0000gn/T/ipykernel_52177/4182074172.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  mask_diff = torch.tensor(1 - label_mat_train,dtype=bool).flatten()\n"
     ]
    }
   ],
   "source": [
    "disMat = torch.cdist(output,output).flatten()\n",
    "mask_same = torch.tensor(label_mat_train - torch.diag(torch.ones(450)),dtype=bool).flatten()\n",
    "mask_diff = torch.tensor(1 - label_mat_train,dtype=bool).flatten()\n",
    "sameComp = disMat[mask_same].detach().numpy()\n",
    "diffComp = disMat[mask_diff].detach().numpy()\n",
    "weightsSame = np.ones_like(sameComp) / len(sameComp)\n",
    "weightsDiff = np.ones_like(diffComp) / len(diffComp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00055376854"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(diffComp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(195750,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diffComp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.000542997"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(sameComp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=float64), array([0.]), <BarContainer object of 0 artists>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(sameComp,bins=np.arange(0,np.max(sameComp),0.01),weights=weightsSame,log = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=float64), array([0.]), <BarContainer object of 0 artists>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#from matplotlib.pyplot import figure\n",
    "#figure(figsize=(10, 8), dpi=80)\n",
    "plt.hist(diffComp,bins=np.arange(0,np.max(diffComp),0.01),weights=weightsDiff,log = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "BigDiffIndices = np.where(disMat.detach().numpy().flatten() > 0.1)[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(BigDiffIndices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vizMat = np.zeros([30,30])\n",
    "vizMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in BigDiffIndices:\n",
    "    row, col = divmod(index,600)\n",
    "    cat1, cat2 = int(label_np[row]),int(label_np[col])\n",
    "    #print(cat1,cat2, (cat1 == cat2))\n",
    "    vizMat[cat1,cat2] += 1\n",
    "    vizMat[cat2,cat1] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y9/sgsdqvs575j76jqnz728mwkh0000gn/T/ipykernel_52177/2351932576.py:1: RuntimeWarning: invalid value encountered in divide\n",
      "  vizMat = vizMat / np.max(vizMat)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vizMat = vizMat / np.max(vizMat)\n",
    "vizMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa75a0d6fe0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaMAAAGkCAYAAACckEpMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/P9b71AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAYX0lEQVR4nO3df2hV9/3H8df1R261zb1ZjMnNnVcXbatbrRlzmgVb12IwyUD8NbA/BlpE0cUyTbsWR+uPbZDNgpQWV/+arlC1E6pSYYLGJtItOrSKyNZgsmxGzI2tkHtirFcxn+8fw7vv1fgjem/eyc3zAYd6zz333veHA/fZm3uiPuecEwAAhoZYDwAAADECAJgjRgAAc8QIAGCOGAEAzBEjAIA5YgQAMEeMAADmiBEAwBwxAgCYGzAx2rJli77zne/okUceUUlJif7+979bj5RWGzZskM/nS9omTZpkPVbKHTlyRHPmzFE4HJbP59PevXuT7nfOad26dSosLNSIESNUVlams2fP2gybQvda95IlS247/xUVFTbDplBNTY2mTZum7Oxs5efna968eWpsbEw65urVq6qqqtKoUaP02GOPaeHChWpvbzeaODXuZ93PPffcbed8xYoVRhP3vQERo48//ljV1dVav369vvjiCxUXF6u8vFwXL160Hi2tnnrqKbW1tSW2zz//3HqklOvq6lJxcbG2bNnS4/2bNm3Se++9p61bt+rYsWN69NFHVV5erqtXr/bxpKl1r3VLUkVFRdL537lzZx9OmB719fWqqqrS0aNHdfDgQV2/fl2zZ89WV1dX4pg1a9bo008/1e7du1VfX68LFy5owYIFhlM/vPtZtyQtW7Ys6Zxv2rTJaGIDbgCYPn26q6qqSty+ceOGC4fDrqamxnCq9Fq/fr0rLi62HqNPSXJ79uxJ3O7u7nahUMi98847iX0dHR3O7/e7nTt3GkyYHreu2znnFi9e7ObOnWsyT1+6ePGik+Tq6+udc/89v8OHD3e7d+9OHPPPf/7TSXINDQ1WY6bcret2zrkf//jH7he/+IXdUMb6/Seja9eu6cSJEyorK0vsGzJkiMrKytTQ0GA4WfqdPXtW4XBY48eP18svv6xz585Zj9SnWlpaFI1Gk859MBhUSUlJxp97Saqrq1N+fr4mTpyolStX6tKlS9YjpVwsFpMk5ebmSpJOnDih69evJ53zSZMmaezYsRl1zm9d900fffSR8vLyNHnyZK1du1ZXrlyxGM/EMOsB7uXrr7/WjRs3VFBQkLS/oKBAX375pdFU6VdSUqLt27dr4sSJamtr08aNG/Xss8/qzJkzys7Oth6vT0SjUUnq8dzfvC9TVVRUaMGCBSoqKlJzc7N+9atfqbKyUg0NDRo6dKj1eCnR3d2t1atXa8aMGZo8ebKk/57zrKws5eTkJB2bSee8p3VL0ksvvaRx48YpHA7r9OnTevPNN9XY2KhPPvnEcNq+0+9jNFhVVlYm/jxlyhSVlJRo3Lhx+vOf/6ylS5caToa+8MILLyT+/PTTT2vKlCmaMGGC6urqNGvWLMPJUqeqqkpnzpzJyO9C7+ZO616+fHniz08//bQKCws1a9YsNTc3a8KECX09Zp/r9z+my8vL09ChQ2+7mqa9vV2hUMhoqr6Xk5OjJ598Uk1NTdaj9Jmb53ewn3tJGj9+vPLy8jLm/K9atUr79+/XZ599pjFjxiT2h0IhXbt2TR0dHUnHZ8o5v9O6e1JSUiJJGXPO76XfxygrK0tTp05VbW1tYl93d7dqa2tVWlpqOFnfunz5spqbm1VYWGg9Sp8pKipSKBRKOvee5+nYsWOD6txL0vnz53Xp0qUBf/6dc1q1apX27Nmjw4cPq6ioKOn+qVOnavjw4UnnvLGxUefOnRvQ5/xe6+7JqVOnJGnAn/P7Zn0Fxf3YtWuX8/v9bvv27e4f//iHW758ucvJyXHRaNR6tLR57bXXXF1dnWtpaXF//etfXVlZmcvLy3MXL160Hi2lOjs73cmTJ93JkyedJLd582Z38uRJ95///Mc559zvfvc7l5OT4/bt2+dOnz7t5s6d64qKitw333xjPPnDudu6Ozs73euvv+4aGhpcS0uLO3TokPvBD37gnnjiCXf16lXr0R/KypUrXTAYdHV1da6trS2xXblyJXHMihUr3NixY93hw4fd8ePHXWlpqSstLTWc+uHda91NTU3u17/+tTt+/LhraWlx+/btc+PHj3czZ840nrzvDIgYOefc+++/78aOHeuysrLc9OnT3dGjR61HSqtFixa5wsJCl5WV5b797W+7RYsWuaamJuuxUu6zzz5zkm7bFi9e7Jz77+Xdb7/9tisoKHB+v9/NmjXLNTY22g6dAndb95UrV9zs2bPd6NGj3fDhw924cePcsmXLMuJ/vnpasyS3bdu2xDHffPON+/nPf+6+9a1vuZEjR7r58+e7trY2u6FT4F7rPnfunJs5c6bLzc11fr/fPf744+6Xv/yli8VitoP3IZ9zzvXd5zAAAG7X778zAgBkPmIEADBHjAAA5ogRAMAcMQIAmCNGAABzAypG8XhcGzZsUDwetx6lT7Fu1j0YsO7Bte5bDajfM/I8T8FgULFYTIFAwHqcPsO6WfdgwLoH17pvNaA+GQEAMhMxAgCY63f/nlF3d7cuXLig7Oxs+Xy+pPs8z0v672DBuln3YMC6M2/dzjl1dnYqHA5ryJC7f/bpd98ZnT9/XpFIxHoMAECKtLa23vPfb+p3n4xu/pPara2tg/rLPAAY6DzPUyQSSbyv303aYrRlyxa98847ikajKi4u1vvvv6/p06ff83E3fzQXCASIEQBkgFu/culJWi5g+Pjjj1VdXa3169friy++UHFxscrLy3Xx4sV0vBwAYIBLS4w2b96sZcuW6ZVXXtH3vvc9bd26VSNHjtQf//jHdLwcAGCAS3mMrl27phMnTqisrOx/LzJkiMrKytTQ0HDb8fF4XJ7nJW0AgMEl5TH6+uuvdePGDRUUFCTtLygoUDQave34mpoaBYPBxMaVdAAw+Jj/0uvatWsVi8USW2trq/VIAIA+lvKr6fLy8jR06FC1t7cn7W9vb1coFLrteL/fL7/fn+oxAAADSMo/GWVlZWnq1Kmqra1N7Ovu7lZtba1KS0tT/XIAgAyQlt8zqq6u1uLFi/XDH/5Q06dP17vvvquuri698sor6Xg5AMAAl5YYLVq0SF999ZXWrVunaDSq73//+zpw4MBtFzUAACD1w7+bjn/bAwAyQ2/ez82vpgMAgBgBAMwRIwCAOWIEADBHjAAA5ogRAMAcMQIAmCNGAABzxAgAYI4YAQDMESMAgDliBAAwR4wAAOaIEQDAHDECAJgjRgAAc8QIAGCOGAEAzBEjAIA5YgQAMEeMAADmiBEAwBwxAgCYI0YAAHPECABgjhgBAMwRIwCAOWIEADBHjAAA5ogRAMAcMQIAmCNGAABzxAgAYI4YAQDMESMAgDliBAAwR4wAAOaIEQDAHDECAJgjRgAAc8QIAGCOGAEAzBEjAIA5YgQAMEeMAADmiBEAwBwxAgCYI0YAAHPECABgjhgBAMwRIwCAuZTHaMOGDfL5fEnbpEmTUv0yAIAMMiwdT/rUU0/p0KFD/3uRYWl5GQBAhkhLJYYNG6ZQKJSOpwYAZKC0fGd09uxZhcNhjR8/Xi+//LLOnTt3x2Pj8bg8z0vaAACDS8pjVFJSou3bt+vAgQP64IMP1NLSomeffVadnZ09Hl9TU6NgMJjYIpFIqkcCAPRzPuecS+cLdHR0aNy4cdq8ebOWLl162/3xeFzxeDxx2/M8RSIRxWIxBQKBdI4GAEgjz/MUDAbv6/087VcW5OTk6Mknn1RTU1OP9/v9fvn9/nSPAQDox9L+e0aXL19Wc3OzCgsL0/1SAIABKuUxev3111VfX69///vf+tvf/qb58+dr6NChevHFF1P9UgCADJHyH9OdP39eL774oi5duqTRo0frmWee0dGjRzV69OhUvxQAIEOkPEa7du1K9VMCADIcfzcdAMAcMQIAmCNGAABzxAgAYI4YAQDMESMAgDliBAAwR4wAAOaIEQDAHDECAJgjRgAAc8QIAGCOGAEAzBEjAIA5YgQAMEeMAADmiBEAwBwxAgCYI0YAAHPECABgjhgBAMwRIwCAOWIEADBHjAAA5ogRAMAcMQIAmCNGAABzxAgAYI4YAQDMESMAgDliBAAwR4wAAOaIEQDAHDECAJgjRgAAc8QIAGCOGAEAzBEjAIA5YgQAMEeMAADmiBEAwBwxAgCYI0YAAHPECABgjhgBAMwRIwCAOWIEADBHjAAA5ogRAMAcMQIAmCNGAABzvY7RkSNHNGfOHIXDYfl8Pu3duzfpfuec1q1bp8LCQo0YMUJlZWU6e/ZsquYFAGSgXseoq6tLxcXF2rJlS4/3b9q0Se+99562bt2qY8eO6dFHH1V5ebmuXr360MMCADLTsN4+oLKyUpWVlT3e55zTu+++q7feektz586VJH344YcqKCjQ3r179cILLzzctACAjJTS74xaWloUjUZVVlaW2BcMBlVSUqKGhoYeHxOPx+V5XtIGABhcUhqjaDQqSSooKEjaX1BQkLjvVjU1NQoGg4ktEomkciQAwABgfjXd2rVrFYvFEltra6v1SACAPpbSGIVCIUlSe3t70v729vbEfbfy+/0KBAJJGwBgcElpjIqKihQKhVRbW5vY53mejh07ptLS0lS+FAAgg/T6arrLly+rqakpcbulpUWnTp1Sbm6uxo4dq9WrV+u3v/2tnnjiCRUVFentt99WOBzWvHnzUjk3ACCD9DpGx48f1/PPP5+4XV1dLUlavHixtm/frjfeeENdXV1avny5Ojo69Mwzz+jAgQN65JFHUjc1ACCj+JxzznqI/8/zPAWDQcViMb4/AoABrDfv5+ZX0wEAQIwAAOaIEQDAHDECAJgjRgAAc8QIAGCOGAEAzBEjAIA5YgQAMEeMAADmiBEAwBwxAgCYI0YAAHPECABgjhgBAMwRIwCAOWIEADBHjAAA5ogRAMAcMQIAmCNGAABzxAgAYI4YAQDMESMAgDliBAAwR4wAAOaIEQDAHDECAJgjRgAAc8QIAGCOGAEAzBEjAIA5YgQAMEeMAADmiBEAwBwxAgCYI0YAAHPECABgjhgBAMwRIwCAOWIEADBHjAAA5ogRAMAcMQIAmCNGAABzxAgAYI4YAQDMESMAgDliBAAwR4wAAOaIEQDAXK9jdOTIEc2ZM0fhcFg+n0979+5Nun/JkiXy+XxJW0VFRarmBQBkoF7HqKurS8XFxdqyZcsdj6moqFBbW1ti27lz50MNCQDIbMN6+4DKykpVVlbe9Ri/369QKPTAQwEABpe0fGdUV1en/Px8TZw4UStXrtSlS5fueGw8HpfneUkbAGBwSXmMKioq9OGHH6q2tla///3vVV9fr8rKSt24caPH42tqahQMBhNbJBJJ9UgAgH7O55xzD/xgn0979uzRvHnz7njMv/71L02YMEGHDh3SrFmzbrs/Ho8rHo8nbnuep0gkolgspkAg8KCjAQCMeZ6nYDB4X+/nab+0e/z48crLy1NTU1OP9/v9fgUCgaQNADC4pD1G58+f16VLl1RYWJjulwIADFC9vpru8uXLSZ9yWlpadOrUKeXm5io3N1cbN27UwoULFQqF1NzcrDfeeEOPP/64ysvLUzo4ACBz9DpGx48f1/PPP5+4XV1dLUlavHixPvjgA50+fVp/+tOf1NHRoXA4rNmzZ+s3v/mN/H5/6qYGAGSUh7qAIR1684UXAKD/6lcXMAAAcC/ECABgjhgBAMwRIwCAOWIEADBHjAAA5ogRAMAcMQIAmCNGAABzxAgAYI4YAQDMESMAgDliBAAwR4wAAOaIEQDAHDECAJgjRgAAc8QIAGCOGAEAzBEjAIA5YgQAMEeMAADmiBEAwBwxAgCYI0YAAHPECABgjhgBAMwRIwCAOWIEADBHjAAA5ogRAMAcMQIAmCNGAABzxAgAYI4YAQDMESMAgDliBAAwR4wAAOaIEQDAHDECAJgjRgAAc8QIAGCOGAEAzBEjAIA5YgQAMEeMAADmiBEAwBwxAgCYI0YAAHPECABgjhgBAMz1KkY1NTWaNm2asrOzlZ+fr3nz5qmxsTHpmKtXr6qqqkqjRo3SY489poULF6q9vT2lQwMAMkuvYlRfX6+qqiodPXpUBw8e1PXr1zV79mx1dXUljlmzZo0+/fRT7d69W/X19bpw4YIWLFiQ8sEBAJnD55xzD/rgr776Svn5+aqvr9fMmTMVi8U0evRo7dixQz/96U8lSV9++aW++93vqqGhQT/60Y/u+Zye5ykYDCoWiykQCDzoaAAAY715P3+o74xisZgkKTc3V5J04sQJXb9+XWVlZYljJk2apLFjx6qhoaHH54jH4/I8L2kDAAwuDxyj7u5urV69WjNmzNDkyZMlSdFoVFlZWcrJyUk6tqCgQNFotMfnqampUTAYTGyRSORBRwIADFAPHKOqqiqdOXNGu3bteqgB1q5dq1gslthaW1sf6vkAAAPPsAd50KpVq7R//34dOXJEY8aMSewPhUK6du2aOjo6kj4dtbe3KxQK9fhcfr9ffr//QcYAAGSIXn0ycs5p1apV2rNnjw4fPqyioqKk+6dOnarhw4ertrY2sa+xsVHnzp1TaWlpaiYGAGScXn0yqqqq0o4dO7Rv3z5lZ2cnvgcKBoMaMWKEgsGgli5dqurqauXm5ioQCOjVV19VaWnpfV1JBwAYnHp1abfP5+tx/7Zt27RkyRJJ//2l19dee007d+5UPB5XeXm5/vCHP9zxx3S34tJuAMgMvXk/f6jfM0oHYgQAmaHPfs8IAIBUIEYAAHPECABgjhgBAMwRIwCAOWIEADBHjAAA5ogRAMAcMQIAmCNGAABzxAgAYI4YAQDMESMAgDliBAAwR4wAAOaIEQDAHDECAJgjRgAAc8QIAGCOGAEAzBEjAIA5YgQAMEeMAADmiBEAwBwxAgCYI0YAAHPECABgjhgBAMwRIwCAOWIEADBHjAAA5ogRAMAcMQIAmCNGAABzxAgAYI4YAQDMESMAgDliBAAwR4wAAOaIEQDAHDECAJgjRgAAc8QIAGCOGAEAzBEjAIA5YgQAMEeMAADmiBEAwBwxAgCYI0YAAHPECABgrlcxqqmp0bRp05Sdna38/HzNmzdPjY2NScc899xz8vl8SduKFStSOjQAILP0Kkb19fWqqqrS0aNHdfDgQV2/fl2zZ89WV1dX0nHLli1TW1tbYtu0aVNKhwYAZJZhvTn4wIEDSbe3b9+u/Px8nThxQjNnzkzsHzlypEKhUGomBABkvIf6zigWi0mScnNzk/Z/9NFHysvL0+TJk7V27VpduXLljs8Rj8fleV7SBgAYXHr1yej/6+7u1urVqzVjxgxNnjw5sf+ll17SuHHjFA6Hdfr0ab355ptqbGzUJ5980uPz1NTUaOPGjQ86BgAgA/icc+5BHrhy5Ur95S9/0eeff64xY8bc8bjDhw9r1qxZampq0oQJE267Px6PKx6PJ257nqdIJKJYLKZAIPAgowEA+gHP8xQMBu/r/fyBPhmtWrVK+/fv15EjR+4aIkkqKSmRpDvGyO/3y+/3P8gYAIAM0asYOef06quvas+ePaqrq1NRUdE9H3Pq1ClJUmFh4QMNCADIfL2KUVVVlXbs2KF9+/YpOztb0WhUkhQMBjVixAg1Nzdrx44d+slPfqJRo0bp9OnTWrNmjWbOnKkpU6akZQEAgIGvV98Z+Xy+Hvdv27ZNS5YsUWtrq372s5/pzJkz6urqUiQS0fz58/XWW2/d9/c/vfkZIwCg/0rbd0b36lYkElF9fX1vnhIAAP5uOgCAPWIEADBHjAAA5ogRAMAcMQIAmCNGAABzxAgAYI4YAQDMESMAgDliBAAwR4wAAOaIEQDAHDECAJgjRgAAc8QIAGCOGAEAzBEjAIA5YgQAMEeMAADmiBEAwBwxAgCYI0YAAHPECABgjhgBAMwRIwCAOWIEADBHjAAA5ogRAMAcMQIAmCNGAABzxAgAYI4YAQDMESMAgDliBAAwR4wAAOaIEQDAHDECAJgjRgAAc8QIAGCOGAEAzBEjAIA5YgQAMEeMAADmiBEAwBwxAgCYI0YAAHPECABgjhgBAMwNsx7gVs45SZLnecaTAAAexs338Zvv63fT72LU2dkpSYpEIsaTAABSobOzU8Fg8K7H+Nz9JKsPdXd368KFC8rOzpbP50u6z/M8RSIRtba2KhAIGE3Y91g36x4MWHfmrds5p87OToXDYQ0ZcvdvhfrdJ6MhQ4ZozJgxdz0mEAhk3Em7H6x7cGHdg0umrvten4hu4gIGAIA5YgQAMDegYuT3+7V+/Xr5/X7rUfoU62bdgwHrHlzrvlW/u4ABADD4DKhPRgCAzESMAADmiBEAwBwxAgCYI0YAAHPECABgjhgBAMwRIwCAuf8D2HXJdTxUii0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(vizMat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
