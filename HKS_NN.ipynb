{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bd7c94-affc-482d-b078-4e5b800b4304",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch \n",
    "import torch.nn.functional as F\n",
    "import igl \n",
    "import networkx as nx \n",
    "import numpy as np # np.linalg.eig\n",
    "import scipy as sp\n",
    "from meshplot import plot, subplot, interact\n",
    "import meshplot as mp\n",
    "\n",
    "# igl \n",
    "import os\n",
    "root_folder = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d110bcb9-a9e6-4562-9d66-6f6ad3f32c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch \n",
    "# import numpy as np\n",
    "\n",
    "# # igl \n",
    "# import os\n",
    "# root_folder = os.getcwd()\n",
    "\n",
    "# %run HKS.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca1c1f3-defd-40a8-8cd1-82b13fdaf2a5",
   "metadata": {},
   "source": [
    "**Hyper Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed2e042-8ec0-44af-b64b-f2ad5f4cb6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_dir = '\\SHREC11'\n",
    "NUM_MESHES = 600 \n",
    "path_to_labels = os.path.join(root_folder, \"SHREC11\", \"labels.txt\")\n",
    "train_size = int(.8*NUM_MESHES) # set aside train (80% )and test (20%) data \n",
    "\n",
    "# set values of t \n",
    "ts= [0.001, 0.01, 0.1, 1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38946ceb-7243-4de2-8daa-83923549ab68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert mesh to networkx graph\n",
    "\n",
    "def do_task(num):\n",
    "    v, f = igl.read_triangle_mesh(os.path.join(root_folder, \"SHREC11\", \"T\"+str(num)+\".obj\"))\n",
    "    # Mesh in (v,f)\n",
    "    adj_mat = igl.adjacency_matrix(f) # this gets me the adj_mat for this mesh \n",
    "    # print(\"type\", type(adj_mat)) # type <class 'scipy.sparse._csc.csc_matrix'>\n",
    "    \n",
    "    G = nx.from_scipy_sparse_array(adj_mat) # creates a new graph from an adj matrix given as a Scipy sparse array \n",
    "    # print(\"G\", G)\n",
    "    \n",
    "    L = nx.laplacian_matrix(G).toarray() # get Laplacian matrix  \n",
    "    # print(\"L\", L)\n",
    "    \n",
    "    # get eigenvalues from graph Laplacian \n",
    "    eigen_values = np.linalg.eigvals(L)\n",
    "    # print(\"eigen_values\", eigen_values)\n",
    "    # print(\"eigen_values type\", type(eigen_values)) # ndarray\n",
    "    # print(\"eigen_values len\", len(eigen_values)) # 252 nodes hence len is 252 \n",
    "    \n",
    "    # compute e^t*eigen_value\n",
    "    \n",
    "    HKS = [] \n",
    "    \n",
    "    for t in ts:\n",
    "        t_eigen_values = t*eigen_values # an array where each lambda is multiplied by t \n",
    "        # print(\"t_eigen_values\", t*eigen_values)\n",
    "\n",
    "        h_t = np.mean(np.exp(t_eigen_values)) # get average to compute h(t) \n",
    "        # print(\"h_t\", h_t)\n",
    "        \n",
    "        HKS.append(h_t) \n",
    "        \n",
    "    return HKS \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e4cf42-1c91-431e-8887-535e736f2392",
   "metadata": {},
   "outputs": [],
   "source": [
    "HKS_all = [] \n",
    "\n",
    "for i in range(600):\n",
    "    HKS = do_task(i)\n",
    "    HKS_all.append(HKS)\n",
    "    \n",
    "# print(\"HKS len\", len(HKS_all))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00e0c05-087f-4915-b2e2-b7176ca89d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I have a list that contains the HKS vectors for each mesh, and I will \n",
    "# convert that into a tensor. The objects numbered 0 through 599 are scrambled\n",
    "# and not organised by category but there is a labels.txt file that groups them\n",
    "# by category, so using that labels.txt file, I will create a list parallel to the\n",
    "# HKS vectors that contains the group number for each mesh, and convert that into a tensor. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b676d65-150e-4539-b061-6c6fed218883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# organise labels - taken from Davidson and Richard's code \n",
    "def readLbl(size,fileName):\n",
    "    #takes in file name, returns the labels as an array\n",
    "    file1 = open(fileName, 'r')\n",
    "    Lines = file1.readlines()\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    lbls = np.empty([size])\n",
    "    obj_order_by_grp = np.empty([size]) # list of obj name ordered by grp no.\n",
    "    lbls_order_by_grp = np.empty([size])  # list of grps ordered by grp no.\n",
    "    # Strips the newline character\n",
    "    for line in Lines:\n",
    "        count += 1\n",
    "        text = line.strip()[1:].split('.')\n",
    "        text[1] = text[1].split(' ')[1]\n",
    "        \n",
    "        # list of obj name ordered by grp no.\n",
    "        obj_order_by_grp[count-1] = int(text[0])\n",
    "        \n",
    "        # list of grps ordered by grp no.\n",
    "        lbls_order_by_grp[count-1] = int(text[1])\n",
    "        \n",
    "        # parallel list to HKS - ordered by object no.\n",
    "        lbls[int(text[0])] = int(text[1])\n",
    "        #print(\"Line{}: {}\".format(count, )))\n",
    "        \n",
    "        # file1.close()\n",
    "    return lbls, obj_order_by_grp, lbls_order_by_grp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae39de89-dc32-40c0-bb58-ce08ea30a967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fName_labels = mesh_dir + 'labels.txt'\n",
    "labels_np, obj_order_by_grp, lbls_order_by_grp = readLbl(NUM_MESHES, path_to_labels)\n",
    "\n",
    "# print(\"obj_order_by_grp\", obj_order_by_grp)\n",
    "# print(\"lbls_order_by_grp\", lbls_order_by_grp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24eb3152-cc3c-4f83-ac79-6060ec9410ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain labels of group 0 and 1 from larger np.arr, put them in labels_binary\n",
    "# => get a np.arr that is [0,0..0,1,1..1]\n",
    "labels_binary = lbls_order_by_grp[:40] # type: ndarray \n",
    "\n",
    "print(\"labels_binary\", type(labels_binary))\n",
    "print(\"labels_binary\", labels_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735cc398-4ceb-4a56-a268-5a0881182217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a np.arr of meshes whose groups are 0 and 1\n",
    "# this is parallel to [0,0..0,1,1..1]\n",
    "obj_order_by_grp_binary = obj_order_by_grp[:40]\n",
    "\n",
    "# convert all floats in np array to int \n",
    "a = obj_order_by_grp_binary.astype(int)\n",
    "\n",
    "# obtain HKS belonging to group 0 and 1\n",
    "HKS_binary_ls = [] \n",
    "for obj in a.tolist(): # tolist() converts type from np.arr to python list \n",
    "    el = HKS_all[obj]\n",
    "    HKS_binary_ls.append(el)\n",
    "\n",
    "# convert HKS_binary_ls back to np.array \n",
    "HKS_binary = np.array(HKS_binary_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec872aa3-4667-4b5a-b1ed-852cc17ec3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"pre shuffle:\", labels_binary)\n",
    "# print(\"pre shuffle:\", HKS_binary)\n",
    "\n",
    "# shuffle two np arrays together\n",
    "rand_indexes = np.arange(len(labels_binary))\n",
    "np.random.shuffle(rand_indexes)\n",
    "labels_binary=labels_binary[rand_indexes]\n",
    "HKS_binary=HKS_binary[rand_indexes]\n",
    "\n",
    "# print(\"post shuffle:\", labels_binary)\n",
    "# print(\"post shuffle:\", HKS_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa039a7f-8e03-48cb-9c62-d31ab5c8bfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training size is hardcoded bc small dataset \n",
    "labels_binary_train = torch.tensor(labels_binary[:int(.8*40)]).float()\n",
    "torch.reshape(labels_binary_train, (32,1))\n",
    "labels_binary_test = torch.tensor(labels_binary[int(.8*40):]).float()\n",
    "\n",
    "HKS_binary_train = torch.tensor(HKS_binary[:int(.8*40)]).float()\n",
    "HKS_binary_test = torch.tensor(HKS_binary[int(.8*40):]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a976c3a1-6695-44be-8be2-b376955c286b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary classifier \n",
    "hks_binary_classifier = torch.nn.Sequential( \n",
    "    torch.nn.Linear(4, 6), # takes in vector of size 8 (mine is 4), 16 means weight layer \n",
    "    torch.nn.Sigmoid(), # activation function, can use sigmoid etc \n",
    "    torch.nn.Linear(6, 1), #(x,y) -> y is the size of my output I'm doing a linear classifier (binary now, later 25 categories)\n",
    "    torch.nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f0e11c-de07-45f6-82b7-155f66157008",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_binary_train = labels_binary_train.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fbdf02-7a07-4443-b684-54de0db8a0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop \n",
    "optimizer = optim.Adam(hks_binary_classifier.parameters(), lr = 0.0001)\n",
    "for i in range(2000):\n",
    "    optimizer.zero_grad()\n",
    "    # print(HKS_binary_train)\n",
    "    output = hks_binary_classifier.forward(HKS_binary_train)\n",
    "    # print(output) \n",
    "    loss = F.binary_cross_entropy(output,labels_binary_train)\n",
    "    loss.backward()\n",
    "    print(loss)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1ff028-75bf-4947-abf6-982611a04402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi-class classifier \n",
    "hks_binary_classifier = torch.nn.Sequential( \n",
    "    torch.nn.Linear(4, 6), # takes in vector of size 8 (mine is 4), 16 means weight layer \n",
    "    torch.nn.Tanh(), # activation function, can use sigmoid etc \n",
    "    torch.nn.Linear(6, 1), #(x,y) -> y is the size of my output I'm doing a linear classifier (binary now, later 25 categories)\n",
    "    torch.nn.Softmax()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022ce45c-fde0-4f2f-b200-11b162d7d17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cast to tensor for all 600 groups\n",
    "# note: everything is scrambled (group wise)\n",
    "# arranged in order from T0-T599 \n",
    "labels_train = torch.tensor(labels_np[:train_size]).float()\n",
    "labels_test = torch.tensor(labels_np[train_size:]).float()\n",
    "\n",
    "HKS_all_train = torch.tensor(HKS_all[:train_size]).float()\n",
    "HKS_all_test = torch.tensor(HKS_all[train_size:]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b59a68b-d19e-4930-bca1-2f5b2f9c63a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#davidson and richard\n",
    "optimizer = optim.Adam(g.weights + n.weights,lr = 0.0001)\n",
    "for i in range(100000):\n",
    "    optimizer.zero_grad()\n",
    "    output = n.forward(g.forward(normed_adjMats_tr,node_sigs_tr))\n",
    "    loss = lossF(output,label_mat_tr)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc9f43d-1500-4d81-8dfb-c48fea5af0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple network \n",
    "hks_classifier = torch.nn.Sequential( \n",
    "    torch.nn.Linear(4, 6), # takes in vector of size 8 (mine is 4), 16 means weight layer \n",
    "    torch.nn.Tanh(), # activation function, can use sigmoid etc \n",
    "    torch.nn.Linear(6, ), #(x,y) -> y is the size of my output I'm doing a linear classifier (binary now, later 25 categories)\n",
    "    torch.nn.Tanh(),\n",
    ")\n",
    "\n",
    "# how to apply\n",
    "# one hot encoding?? \n",
    "# this is probably what I want \n",
    "# output size is num. of categories (beginning 2, later 600 then 2400) \n",
    "\n",
    "# loss function:\n",
    "# how far away your predictions are from actual labels\n",
    "# with 1 hot, subtract predicted from actual value, take absolute value (diff) \n",
    "# take sum of the differences\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36734cac-8c29-470b-b175-bd0017ada567",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
