{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "File `'alternate_data.ipynb'` not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "File \u001b[0;32m~/.conda/envs/TSM/lib/python3.10/site-packages/IPython/core/magics/execution.py:696\u001b[0m, in \u001b[0;36mExecutionMagics.run\u001b[0;34m(self, parameter_s, runner, file_finder)\u001b[0m\n\u001b[1;32m    695\u001b[0m     fpath \u001b[38;5;241m=\u001b[39m arg_lst[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 696\u001b[0m     filename \u001b[38;5;241m=\u001b[39m \u001b[43mfile_finder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.conda/envs/TSM/lib/python3.10/site-packages/IPython/utils/path.py:90\u001b[0m, in \u001b[0;36mget_py_filename\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m py_name\n\u001b[0;32m---> 90\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile `\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m` not found.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m name)\n",
      "\u001b[0;31mOSError\u001b[0m: File `'alternate_data.ipynb'` not found.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      8\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrun\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhelpers_preproc.ipynb\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_line_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrun\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43malternate_data.ipynb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/TSM/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2369\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2367\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_ns\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_local_scope(stack_depth)\n\u001b[1;32m   2368\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[0;32m-> 2369\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2370\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.conda/envs/TSM/lib/python3.10/site-packages/IPython/core/magics/execution.py:707\u001b[0m, in \u001b[0;36mExecutionMagics.run\u001b[0;34m(self, parameter_s, runner, file_finder)\u001b[0m\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnt\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m re\u001b[38;5;241m.\u001b[39mmatch(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m^\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.*\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m$\u001b[39m\u001b[38;5;124m\"\u001b[39m,fpath):\n\u001b[1;32m    706\u001b[0m         warn(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFor Windows, use double quotes to wrap a filename: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124mun \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmypath\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mmyfile.py\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 707\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    708\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    709\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m fpath \u001b[38;5;129;01min\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mmeta_path:\n",
      "\u001b[0;31mException\u001b[0m: File `'alternate_data.ipynb'` not found."
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import torch\n",
    "import numpy as np\n",
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "%run helpers_preproc.ipynb\n",
    "%run alternate_data.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origDataDir = 'SHREC11/'\n",
    "newDataDir = 'SHREC11_plus/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate additional data and update label\n",
    "origLabel = np.array(readLbl(600,origDataDir + 'labels.txt'),dtype = int) #first take in the original labels\n",
    "newLabelFile = open(newDataDir + \"labels.txt\", \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radiuss = [0.0002,0.0004,0.0008,0.0016]\n",
    "\n",
    "for i in range(600):\n",
    "    #First create the new obj file\n",
    "    origN = origDataDir + 'T' + str(i) + '.obj'\n",
    "    \n",
    "    for j in range(len(radiuss)):\n",
    "        radius = radiuss[j]\n",
    "        newN = newDataDir + 'T' + str(i+600*(j)) + '.obj'\n",
    "    \n",
    "        #newLabelFile.write(\"T\" + str(i) + \".obj\" + \" \" + str(origLabel[i]) + \"\\n\")\n",
    "        if not (write_new_files(origN,newN,radius)):\n",
    "            print('Data generation failed on ' , i)\n",
    "        \n",
    "        newLabelFile.write(\"T\" + str(i + 600*(j)) + \".obj\" + \" \" + str(origLabel[i]) + \"\\n\")\n",
    "\n",
    "    \n",
    "newLabelFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in the data, get normalized adjacency (NxN)\n",
    "num_meshes = 600 * 4\n",
    "train_size = 450 * 4\n",
    "test_size = 150 * 4\n",
    "mesh_dir = 'SHREC11_plus/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_swaps = 10000\n",
    "\n",
    "labels = np.array(readLbl(num_meshes,mesh_dir+'labels.txt'))\n",
    "\n",
    "for swap_idx in range(num_swaps):\n",
    "    idxA = random.randint(0,num_meshes-1)\n",
    "    idxB = random.randint(0,num_meshes-1)\n",
    "    \n",
    "    if idxA != idxB:\n",
    "        labelA = labels[idxA]\n",
    "        labelB = labels[idxB]\n",
    "        labels[idxA] = labelB\n",
    "        labels[idxB] = labelA\n",
    "\n",
    "        #change filenames\n",
    "        os.rename(mesh_dir+'T' + str(idxA) + '.obj',mesh_dir+'temp.obj')\n",
    "        os.rename(mesh_dir+'T' + str(idxB) + '.obj',mesh_dir+'T' + str(idxA) + '.obj')\n",
    "        os.rename(mesh_dir+'temp.obj',mesh_dir+'T' + str(idxB) + '.obj')\n",
    "\n",
    "newLabelFile = open(newDataDir + \"labels.txt\", \"w\")\n",
    "for i in range(num_meshes):\n",
    "        newLabelFile.write(\"T\" + str(i) + \".obj\" + \" \" + str(labels[i]) + \"\\n\")\n",
    "\n",
    "\n",
    "newLabelFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_np = np.array(readLbl(num_meshes,mesh_dir+'labels.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_sigs_list = []\n",
    "normed_adjMats_list = []\n",
    "\n",
    "for i in range(num_meshes):\n",
    "    fName = 'T' + str(i) + '.obj'\n",
    "    adj_noscale_read = obj_2_adj_noscale(mesh_dir + fName)\n",
    "    adj_scaled_read = obj_2_adj(mesh_dir + fName)\n",
    "\n",
    "    if (adj_scaled_read.shape[0] < 252):\n",
    "        adj_noscale = np.empty([252,252])\n",
    "        adj_scaled = np.empty([252,252])\n",
    "    else:\n",
    "        adj_noscale = adj_noscale_read\n",
    "        adj_scaled = adj_scaled_read\n",
    "\n",
    "    adj_normalized = adj_noscale / np.reshape(np.sum(adj_noscale,axis = 1),[adj_noscale.shape[0],1])\n",
    "\n",
    "    #node level signal extraction\n",
    "    node_degs = np.sum(adj_noscale,axis = 0)\n",
    "    node_neigh_max = np.max(adj_scaled,axis = 0)\n",
    "    #node_neigh_min = np.min(adj_scaled,axis = 0)\n",
    "    node_neigh_sum = np.sum(adj_scaled,axis = 0)\n",
    "    node_neigh_mean = np.sum(adj_scaled,axis = 0) / node_degs\n",
    "\n",
    "    node_sig = np.stack([node_degs,node_neigh_max,node_neigh_sum,node_neigh_mean],axis = 1)\n",
    "    \n",
    "    node_sigs_list.append(node_sig)\n",
    "    normed_adjMats_list.append(adj_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normed_adjMats = np.nan_to_num(np.stack(normed_adjMats_list))\n",
    "node_sigs = np.nan_to_num(np.stack(node_sigs_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature_mean = np.reshape(np.mean(node_sigs,axis = 1),[num_meshes,1,5])\n",
    "#node_sigs = node_sigs - feature_mean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_sigs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normed_adjMats_tr = normed_adjMats[:train_size,:,:]\n",
    "node_sigs_tr = node_sigs[:train_size,:,:]\n",
    "label_np_tr = label_np[:train_size]\n",
    "\n",
    "normed_adjMats_ts = normed_adjMats[train_size:,:,:]\n",
    "node_sigs_ts = node_sigs[train_size:,:,:]\n",
    "label_np_ts = label_np[train_size:]\n",
    "\n",
    "label_mat_tr = torch.tensor(np.where(igl.all_pairs_distances(label_np_tr,label_np_tr,False) > 0.5,0,1)).float()\n",
    "label_mat_ts = torch.tensor(np.where(igl.all_pairs_distances(label_np_ts,label_np_ts,False) > 0.5,0,1)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normed_adjMats_tr = torch.tensor(normed_adjMats_tr).float()\n",
    "node_sigs_tr = torch.tensor(node_sigs_tr).float()\n",
    "label_tr = torch.tensor(label_np_tr).float()\n",
    "\n",
    "normed_adjMats_ts = torch.tensor(normed_adjMats_ts).float()\n",
    "node_sigs_ts = torch.tensor(node_sigs_ts).float()\n",
    "label_ts = torch.tensor(label_np_ts).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label_mat_train = form_label_matrix(label_mat, train_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normed_adjMats_list_train, node_sigs_list_train = prep_data(train_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normed_adjMats_train = np.stack(normed_adjMats_list_train)\n",
    "#node_sigs_train = np.stack(node_sigs_list_train)\n",
    "\n",
    "#normed_adjMats_train = torch.tensor(normed_adjMats_train,requires_grad=False).float()\n",
    "#node_sigs_train = torch.tensor(node_sigs_train,requires_grad=False).float()\n",
    "\n",
    "#normed_adjMats_train = torch.nan_to_num(normed_adjMats_train,0,0,0)\n",
    "#node_sigs_train = torch.nan_to_num(node_sigs_train,0,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_sigs_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run NNs.ipynb\n",
    "g = GCN(4,[5,5,5,5])\n",
    "n = MLP(252*5,[5,5,5,5])\n",
    "output1 = g.forward(normed_adjMats_tr,node_sigs_tr)\n",
    "output2 = n.forward(output1)\n",
    "print(output1.shape)\n",
    "print(output2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def lossF(features,lbl_mat):\n",
    "    disMat = torch.cdist(features,features)\n",
    "    sameType = disMat * (lbl_mat-torch.diag(torch.ones(lbl_mat.shape[0])))\n",
    "    diffType = disMat * (1-lbl_mat)\n",
    "\n",
    "    diffTypeScaled = diffType * torch.exp(-diffType)\n",
    "    diffTypeScaledMean = torch.sum(diffTypeScaled)/ torch.count_nonzero(diffTypeScaled)\n",
    "    diffTypeMean = torch.sum(diffType)/ torch.count_nonzero(diffType)\n",
    "\n",
    "    sameTypeMean = torch.sum(sameType) / torch.count_nonzero(sameType)\n",
    "    sameTypeStd = torch.sum((sameType - sameTypeMean)**2) / torch.count_nonzero(sameType)\n",
    "\n",
    "    toRet = sameTypeMean-diffTypeMean + 0.01 * torch.sqrt(sameTypeStd)\n",
    "    #toRet = -(sameTypeMean-diffTypeMean)**2 #+ 0.5*(sameTypeMean + 0.01 * torch.sqrt(sameTypeStd))\n",
    "    #toRet = -(sameTypeMean-diffTypeMean)**2 - diffTypeScaledMean + 0.5 * torch.sqrt(sameTypeStd)\n",
    "    \n",
    "    print(sameTypeMean.detach().numpy(),diffTypeMean.detach().numpy(),torch.sqrt(sameTypeStd).detach().numpy(), toRet.detach().numpy())\n",
    "    return  toRet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(g.weights + n.weights,lr = 0.0001)\n",
    "for i in range(100000):\n",
    "    optimizer.zero_grad()\n",
    "    output = n.forward(g.forward(normed_adjMats_tr,node_sigs_tr))\n",
    "    loss = lossF(output,label_mat_tr)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mn\u001b[49m\u001b[38;5;241m.\u001b[39mforward(g\u001b[38;5;241m.\u001b[39mforward(normed_adjMats_tr,node_sigs_tr))\n\u001b[1;32m      2\u001b[0m output\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'n' is not defined"
     ]
    }
   ],
   "source": [
    "output = n.forward(g.forward(normed_adjMats_tr,node_sigs_tr))\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disMat = torch.cdist(output,output).flatten()\n",
    "mask_same = torch.tensor(label_mat_tr - torch.diag(torch.ones(train_size)),dtype=bool).flatten()\n",
    "mask_diff = torch.tensor(1 - label_mat_tr,dtype=bool).flatten()\n",
    "sameComp = disMat[mask_same].detach().numpy()\n",
    "diffComp = disMat[mask_diff].detach().numpy()\n",
    "weightsSame = np.ones_like(sameComp) / len(sameComp)\n",
    "weightsDiff = np.ones_like(diffComp) / len(diffComp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(sameComp),np.mean(diffComp))\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, sharey=True)\n",
    "ax1.hist(sameComp,bins=np.arange(0,np.max(sameComp),0.01),weights=weightsSame,log = False)\n",
    "ax1.set_title('Same Comp')\n",
    "ax2.hist(diffComp,bins=np.arange(0,np.max(diffComp),0.01),weights=weightsDiff,log = False)\n",
    "ax2.set_title('Diff Comp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = n.forward(g.forward(normed_adjMats_ts,node_sigs_ts))\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disMat = torch.cdist(output,output).flatten()\n",
    "mask_same = torch.tensor(label_mat_ts - torch.diag(torch.ones(test_size)),dtype=bool).flatten()\n",
    "mask_diff = torch.tensor(1 - label_mat_ts,dtype=bool).flatten()\n",
    "sameComp = disMat[mask_same].detach().numpy()\n",
    "diffComp = disMat[mask_diff].detach().numpy()\n",
    "weightsSame = np.ones_like(sameComp) / len(sameComp)\n",
    "weightsDiff = np.ones_like(diffComp) / len(diffComp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(sameComp),np.mean(diffComp))\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, sharey=True)\n",
    "ax1.hist(sameComp,bins=np.arange(0,np.max(sameComp),0.01),weights=weightsSame,log = False)\n",
    "ax1.set_title('Same Comp')\n",
    "ax2.hist(diffComp,bins=np.arange(0,np.max(diffComp),0.01),weights=weightsDiff,log = False)\n",
    "ax2.set_title('Diff Comp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from matplotlib.pyplot import figure\n",
    "#figure(figsize=(10, 8), dpi=80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BigDiffIndices = np.where(disMat.detach().numpy().flatten() > 0.75)[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(BigDiffIndices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vizMat = np.zeros([30,30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separating 30 categories into less categories\n",
    "\n",
    "# for index in BigDiffIndices:\n",
    "#     row, col = divmod(index,test_size)\n",
    "#     cat1, cat2 = int(label_np_ts[row]),int(label_np_ts[col])\n",
    "#     if cat1 == cat2:\n",
    "#         print(cat1, cat2)\n",
    "#     vizMat[cat1,cat2] += 1\n",
    "#     vizMat[cat2,cat1] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vizMat = vizMat / np.max(vizMat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(vizMat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = output.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=3)\n",
    "newX = pca.fit_transform(features)\n",
    "np.sum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_to_show = [0,1,2,3,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPlot = []\n",
    "for i in range(len(indices_to_show)):\n",
    "    a = newX[np.where(label_np_ts == indices_to_show[i]),:]\n",
    "    a = np.reshape(a,[a.shape[1],a.shape[2]])\n",
    "    categories = np.ones([a.shape[0],1]) * indices_to_show[i]\n",
    "    b = np.concatenate((a,categories),axis = 1)\n",
    "    dataPlot.append(b)\n",
    "    \n",
    "dataPlot = np.concatenate(dataPlot,axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPlot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import axes3d\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "ax.scatter(dataPlot[:,0], dataPlot[:,1], dataPlot[:,2], label=dataPlot[:,3], c = dataPlot[:,3], cmap = 'viridis')\n",
    "#ax.axis('off')\n",
    "ax.axes.xaxis.set_ticklabels([])\n",
    "ax.axes.yaxis.set_ticklabels([])\n",
    "ax.axes.zaxis.set_ticklabels([])\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_zlabel('Z')\n",
    "ax.set_title('[0,1,2,3,4]')\n",
    "\n",
    "#plt.legend(loc=\"upper right\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
