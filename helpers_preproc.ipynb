{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import igl\n",
    "import numpy as np\n",
    "import torch\n",
    "import open3d\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy.random import default_rng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "outputs": [],
   "source": [
    "def readLbl(fileName):\n",
    "    #takes in file name, returns the labels as an array\n",
    "    file1 = open(fileName, 'r')\n",
    "    Lines = file1.readlines()\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    lbls = np.empty([600])\n",
    "    # Strips the newline character\n",
    "    for line in Lines:\n",
    "        count += 1\n",
    "        text = line.strip()[1:].split('.')\n",
    "        text[1] = text[1].split(' ')[1]\n",
    "        lbls[int(text[0])] = int(text[1])\n",
    "        #print(\"Line{}: {}\".format(count, )))\n",
    "    return lbls\n",
    "\n",
    "def lbl_2_lblMat(lbls):\n",
    "    #takes in the labels as an array, returns an adjacency matrix between objects of same label\n",
    "    labelMat = igl.all_pairs_distances(lbls,lbls,False)\n",
    "    labelMat = np.where(labelMat > 0.5, 1, 0)\n",
    "    return labelMat\n",
    "\n",
    "def compareGroups(grpa,grpb,lbl,disSMat):\n",
    "    #takes in two group indices, labels and dissimiliarity matrix, returns how similar they are as two groups\n",
    "    grpA_idx = np.reshape(np.where(lbl == grpa),(20,))\n",
    "    grpB_idx = np.reshape(np.where(lbl == grpb),(20,))\n",
    "    A = disSMat[grpA_idx,:]\n",
    "    B = A[:,grpB_idx]\n",
    "\n",
    "    result = np.mean(B)\n",
    "\n",
    "    if (grpa - grpb < 0.1):\n",
    "        result = result * 20 / 19\n",
    "\n",
    "    return result\n",
    "\n",
    "def compareGroupsT(grpa,grpb,lbl,disSMat):\n",
    "    #takes in two group indices, labels and dissimiliarity matrix, returns how similar they are as two groups\n",
    "    grpA_idx = torch.where(lbl == grpa)[0]\n",
    "    grpB_idx = torch.where(lbl == grpb)[0]\n",
    "    A = disSMat[grpA_idx,:]\n",
    "    B = A[:,grpB_idx]\n",
    "\n",
    "    result = torch.mean(B)\n",
    "\n",
    "    if (grpa - grpb < 0.1):\n",
    "        result = result * 20 / 19\n",
    "\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def obj_2_adj(fileName):\n",
    "    #takes in file name, reads the .obj file and returns adjacency matrix scaled with edge values\n",
    "    v, f = igl.read_triangle_mesh(fileName)\n",
    "    distances = igl.all_pairs_distances(v,v,False)\n",
    "    adJ = igl.adjacency_matrix(f).toarray() * distances\n",
    "    return adJ\n",
    "\n",
    "def obj_2_adj_noscale(fileName):\n",
    "    #takes in file name, reads the .obj file and returns adjacency matrix\n",
    "    v, f = igl.read_triangle_mesh(fileName)\n",
    "    distances = igl.all_pairs_distances(v,v,False)\n",
    "    adJ = igl.adjacency_matrix(f).toarray() * distances\n",
    "    adJ = np.where(adJ != 0,1,0)\n",
    "    return adJ\n",
    "\n",
    "def adj_2_features(adj):\n",
    "    #some arbitrary ad-hoc function for extracting features, for testing only\n",
    "\n",
    "    #print([np.mean(adj),np.max(adj),np.std(adj)])\n",
    "    #hist = np.histogram(adj,bins = np.arange(0,0.5,0.02),density=True)\n",
    "    #generic_feat = np.array([np.mean(adj),np.max(adj),np.std(adj)])\n",
    "    hist = np.histogram(adj,bins = 20,density=True)[0]\n",
    "    #print(hist[0])\n",
    "    return hist\n",
    "\n",
    "# get same type of objects\n",
    "def get_same_type(lbls):\n",
    "    type = {}\n",
    "    for i in range(600):\n",
    "        lbl_idx = lbls[i].astype(int)\n",
    "        if bool(type.get(lbl_idx)):\n",
    "            type[lbl_idx].append(i)\n",
    "        else:\n",
    "            type[lbl_idx] = [i]\n",
    "\n",
    "    return type\n",
    "\n",
    "def get_test_train(type):\n",
    "    rand_array = np.random.choice(16, size=(5,1), replace=False)\n",
    "    test = {}\n",
    "    for j in range(len(type)):\n",
    "        for i in range(len(rand_array)):\n",
    "            if bool(test.get(j)):\n",
    "                test[j].append(type[j][rand_array.item(i)])\n",
    "                del type[j][rand_array.item(i)]\n",
    "            else:\n",
    "                test[j] = [type[j][rand_array.item(i)]]\n",
    "                del type[j][rand_array.item(i)]\n",
    "    train = type\n",
    "    return test,train\n",
    "\n",
    "\n",
    "def prep_data(group):\n",
    "    normed_adjMats_list = []\n",
    "    node_sigs_list = []\n",
    "    \n",
    "    for i in range(30):\n",
    "        for j in range(len(group[0])):\n",
    "            fName = 'T' + str(train[i][j]) + '.obj'\n",
    "            adj_noscale_read = obj_2_adj_noscale(mesh_dir + fName)\n",
    "            adj_scaled_read = obj_2_adj(mesh_dir + fName)\n",
    "    \n",
    "            if (adj_scaled_read.shape[0] < 252):\n",
    "                adj_noscale = np.empty([252,252])\n",
    "                adj_scaled = np.empty([252,252])\n",
    "            else:\n",
    "                adj_noscale = adj_noscale_read\n",
    "                adj_scaled = adj_scaled_read\n",
    "    \n",
    "            adj_normalized = adj_noscale / np.reshape(np.sum(adj_noscale,axis = 1),[adj_noscale.shape[0],1])\n",
    "    \n",
    "            #node level signal extraction\n",
    "            node_degs = np.sum(adj_noscale,axis = 0)\n",
    "            node_neigh_max = np.max(adj_scaled,axis = 0)\n",
    "            node_neigh_min = np.min(adj_scaled,axis = 0)\n",
    "            node_neigh_sum = np.sum(adj_scaled,axis = 0)\n",
    "            node_neigh_mean = np.sum(adj_scaled,axis = 0)\n",
    "    \n",
    "            node_sig = np.stack([node_degs,node_neigh_max,node_neigh_min,node_neigh_sum,node_neigh_mean],axis = 1)\n",
    "            node_sigs_list.append(node_sig)\n",
    "    \n",
    "            normed_adjMats_list.append(adj_normalized)\n",
    "    return normed_adjMats_list, node_sigs_list"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def form_label_matrix(label_mat, group):\n",
    "    rows = []\n",
    "    for i in range(30):\n",
    "        for j in range(15):\n",
    "            # delete test obj from label matrix\n",
    "            rows.append(group[i][j])\n",
    "\n",
    "    label_mat = label_mat[:,rows]\n",
    "    label_mat = label_mat[rows, :]\n",
    "    print(label_mat.shape)\n",
    "    return label_mat"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
